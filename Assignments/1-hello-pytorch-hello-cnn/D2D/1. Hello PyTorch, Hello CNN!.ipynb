{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeXa6KG1pR1s"
      },
      "outputs": [],
      "source": [
        "# Google Driveë¥¼ Colab VMì— Mount í•©ë‹ˆë‹¤.\n",
        "# 'ë¡œê·¸ì¸ í•˜ê² ìŠµë‹ˆê¹Œ?' ë¬»ëŠ” ì°½ì´ ë‚˜ì˜¤ë©´ í—ˆê°€ í•´ ì£¼ì„¸ìš”.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ê³¼ì œ íŒŒì¼ì„ ë‹¤ìš´ ë°›ì€ ê²½ë¡œë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "# Google Driveì˜ í´ë” ê²½ë¡œëŠ” /content/drive/My Drive/ ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.\n",
        "# ì¦‰, ë§Œì•½ ë‹¹ì‹ ì´ êµ¬ê¸€ ë“œë¼ì´ë¸Œ ìµœìƒë‹¨ì— ìˆëŠ” 'D2D' í´ë”ì— í•´ë‹¹ íŒŒì¼ì„ ë‹¤ìš´ ë°›ì•˜ë‹¤ê³  í•©ì‹œë‹¤.\n",
        "# ê·¸ëŸ¬ë©´ D2D ì•ˆì—ëŠ” 'Assignment 0' Colab íŒŒì¼ê³¼, datasets í´ë”ê°€ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\n",
        "# ê·¸ë ‡ë‹¤ë©´ ë°‘ì˜ ê²½ë¡œì—ëŠ” '/D2D' ë¼ê³  ì ì–´ì£¼ë©´ ë©ë‹ˆë‹¤. ë§ˆì§€ë§‰ì— '/'ê°€ ì—†ìŒì— ìœ ì˜í•´ ì£¼ì„¸ìš”.\n",
        "FOLDERNAME = None\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# ì´ì œ Driveë¥¼ ë§ˆìš´íŠ¸ í–ˆìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\n",
        "# Python interpreterê°€ Colab VMì´ python filesë¥¼ load í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "# ì´ ì½”ë“œëŠ” CIFAR-10 datasetì´ Driveì— ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME/datasets/\n",
        "!bash get_datasets.sh\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtsHWi7KpR1x"
      },
      "source": [
        "# PyTorch ì‹œì‘í•˜ê¸°\n",
        "**AIKU í•™íšŒì› ì—¬ëŸ¬ë¶„!** ë”¥ëŸ¬ë‹ì„ í–¥í•œ ì—¬ì •ì— ë°œ ë“¤ì¸ ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤ğŸ˜„.\n",
        "\n",
        "í•™íšŒì› ì—¬ëŸ¬ë¶„ì´ ì•ìœ¼ë¡œ ë§ˆì£¼í•˜ê²Œ ë  ì—¬ëŸ¬ ì–´ë ¤ì›€ë“¤ì´ ìˆì„í…ë°, Deep Into Deepì˜ ìˆ˜ì—…ê³¼ ê³¼ì œê°€ ê·¸ ê¸¸ì— ì¡°ê¸ˆì€ ë„ì›€ì´ ë˜ê¸¸ ë°”ëë‹ˆë‹¤.\n",
        "\n",
        "ë³¸ ê³¼ì œëŠ” CS231n, ê³ ë ¤ëŒ€í•™êµ ë”¥ëŸ¬ë‹ ìˆ˜ì—… ë“± ì—¬ëŸ¬ ì¢‹ì€ ê³¼ì œë“¤ì„ í˜¼í•©í•´ ë§Œë“¤ì–´ ì¡ŒìŒì„ ë¯¸ë¦¬ ì•Œë¦½ë‹ˆë‹¤. ê±°ì¸ì˜ ì–´ê¹¨ë¥¼ ë§Œë“¤ì–´ì¤€ ì—¬ëŸ¬ë¶„ ê°ì‚¬í•©ë‹ˆë‹¤!\n",
        "\n",
        "ë‹¤ì‹œ í•œ ë²ˆ ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤! **Happy Hacking!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7e58EDipR1z"
      },
      "source": [
        "## ì™œ Deep Learning frameworksë¥¼ ì¨ì•¼í• ê¹Œìš”?\n",
        "\n",
        "* ìš°ë¦¬ì˜ Codeë¥¼ GPUë¡œ ì‹¤í–‰ ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤! ì´ë¥¼ í†µí•´ ëª¨ë¸ì„ í›¨ì”¬ ë¹ ë¥´ê²Œ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. PyTorchë‚˜ TensorFlowì™€ ê°™ì€ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ë©´ CUDA ì½”ë“œë¥¼ ì§ì ‘ ì‘ì„±í•  í•„ìš” ì—†ì´(ì´ ê°•ì˜ì˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ”) ìì‹ ë§Œì˜ ë§ì¶¤í˜• ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ë¥¼ ìœ„í•´ GPUì˜ ì„±ëŠ¥ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "* ì´ ê°•ì˜ì—ì„œëŠ” í”„ë¡œì íŠ¸ì— ì´ëŸ¬í•œ í”„ë ˆì„ì›Œí¬ ì¤‘ í•˜ë‚˜ (PyTorch)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©í•˜ë ¤ëŠ” ëª¨ë“  ê¸°ëŠ¥ì„ ì§ì ‘ ì‘ì„±í•  ë•Œë³´ë‹¤ ë” íš¨ìœ¨ì ìœ¼ë¡œ ì‹¤í—˜í•  ìˆ˜ ìˆë„ë¡ ì¤€ë¹„í•  ê²ƒì…ë‹ˆë‹¤.\n",
        "\n",
        "* ê±°ì¸ë“¤ì˜ ì–´ê¹¨ ìœ„ì— ì„œ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤! TensorFlowì™€ PyTorchëŠ” ëª¨ë‘ ì—¬ëŸ¬ë¶„ì˜ ì‚¶ì„ í›¨ì”¬ í¸í•˜ê²Œ ë§Œë“¤ì–´ì¤„ í›Œë¥­í•œ í”„ë ˆì„ì›Œí¬ì´ë©°, ì´ì œ ê·¸ ê¸°ëŠ¥ì„ ì´í•´í•˜ì…¨ìœ¼ë‹ˆ ììœ ë¡­ê²Œ ì‚¬ìš©í•˜ì…”ë„ ë©ë‹ˆë‹¤ :)\n",
        "\n",
        "* ë§ˆì§€ë§‰ìœ¼ë¡œ, í•™ê³„ë‚˜ ì—…ê³„ì—ì„œ ì ‘í•  ìˆ˜ ìˆëŠ” ë”¥ ëŸ¬ë‹ ì½”ë“œì— ë…¸ì¶œë˜ê¸°ë¥¼ ë°”ëë‹ˆë‹¤.\n",
        "\n",
        "## PyTorchë€ ë¬´ì—‡ì¼ê¹Œìš”?\n",
        "numpyì˜ ndarrayì™€ ë¹„ìŠ·í•˜ê²Œ ë™ì‘í•˜ëŠ” **Tensor objects**ì— ëŒ€í•´ì„œ ë™ì  computational graphsë¥¼ ì‹¤í–‰í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤. PyTorchëŠ” ì‚¬ëŒì´ ì§ì ‘ backpropagationì„ ê³„ì‚°í•  í•„ìš”ê°€ ì—†ì´ ê°•ë ¥í•œ **ìë™ ë¯¸ë¶„** ì—”ì§„ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "## ì–´ë–»ê²Œ PyTorchë¥¼ ë°°ìš¸ ìˆ˜ ìˆì„ê¹Œìš”?\n",
        "ì´ ê³¼ì œë§Œìœ¼ë¡œëŠ” PyTorch ì „ë°˜ì„ ì´í•´í•˜ëŠ”ë° ì–´ë ¤ì›€ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ì´ ì¶”ì²œë˜ì§€ë§Œ, ë„ì›€ì´ ë  ë§Œí•œ ì‚¬ì´íŠ¸ì™€ í•™ìŠµ ë°©ë²•ì„ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "PyTorch ê³µì‹ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ :\n",
        "https://tutorials.pytorch.kr/beginner/basics/intro.html\n",
        "\n",
        "Stanfordì˜ PyTorch ê°•ì˜ : https://github.com/jcjohnson/pytorch-examples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ulz-ISjJpR10"
      },
      "source": [
        "# ëª©ì°¨\n",
        "ì´ ê³¼ì œëŠ” 6ê°œì˜ íŒŒíŠ¸ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. íŒŒì´í† ì¹˜ë¥¼ ë” ì˜ ì´í•´í•˜ê³  ìµœì¢… í”„ë¡œì íŠ¸ë¥¼ ì¤€ë¹„í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” **ì„¸ ê°€ì§€ ì¶”ìƒí™” ìˆ˜ì¤€**ì—ì„œ íŒŒì´í† ì¹˜ë¥¼ ë°°ìš°ê²Œ ë©ë‹ˆë‹¤.\n",
        "\n",
        "ì´ì— ë”í•´, ìˆ˜ì—… ì‹œê°„ì— ë°°ì› ë˜ **AlexNet**ì„ ì¬êµ¬í˜„í•´ ë³´ë©´ì„œ PyTorchì—ì„œ CNN Layerë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆì„ì§€ ë°°ìš°ê²Œ ë©ë‹ˆë‹¤.\n",
        "\n",
        "1. Part I, ì¤€ë¹„: CIFAR-10 ë°ì´í„° ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "2. Part II, Barebones PyTorch: **ì¶”ìƒí™” ìˆ˜ì¤€ 1**ì˜ ê°€ì¥ ë‚®ì€ ìˆ˜ì¤€ì˜ PyTorch í…ì„œë¡œ ì§ì ‘ ì‘ì—…í•©ë‹ˆë‹¤.\n",
        "3. Part III, PyTorch Module API: **ì¶”ìƒí™” ìˆ˜ì¤€ 2**ì—ì„œëŠ” `nn.Module`ì„ ì‚¬ìš©í•˜ì—¬ ì„ì˜ì˜ ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "4. Part IV, PyTorch Sequential API: **ì¶”ìƒí™” ìˆ˜ì¤€ 3**ì—ì„œëŠ” `nn.Sequential`ì„ ì‚¬ìš©í•˜ì—¬ Linear Feed-Forward Networkë¥¼ ë§¤ìš° í¸ë¦¬í•˜ê²Œ ì •ì˜í•©ë‹ˆë‹¤. + **AlexNet**ì„ ì¬êµ¬í˜„í•´ ë´…ì‹œë‹¤!\n",
        "5. Part V, CIFAR-10 open-ended challenge: CIFAR-10ì—ì„œ ê°€ëŠ¥í•œ í•œ ë†’ì€ ì •í™•ë„ë¥¼ ì–»ê¸° ìœ„í•´ ìì‹ ë§Œì˜ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬í˜„í•˜ì„¸ìš”. Layer, Optimizer, hyperparameters ë˜ëŠ” ê¸°íƒ€ ê³ ê¸‰ ê¸°ëŠ¥ìœ¼ë¡œ ì‹¤í—˜í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "6. Additional Part, Pretrained model ë¶ˆëŸ¬ì˜¤ê¸°: torchvisionì—ì„œ ë‹¤ì–‘í•œ pretrained modelì„ ë¶ˆëŸ¬ë³´ê³  finetuning í•´ ë´…ì‹œë‹¤.\n",
        "\n",
        "ë‹¤ìŒì€ ë¹„êµ í‘œì…ë‹ˆë‹¤:\n",
        "\n",
        "| API | ìœ ì—°ì„± | í¸ì˜ì„± |\n",
        "|---------------|-------------|-------------|\n",
        "| Barebones | ë†’ìŒ | ë‚®ìŒ |\n",
        "| `nn.Module` | ë†’ìŒ | ì¤‘ê°„ |\n",
        "| `nn.Sequential` | ë‚®ìŒ | ë†’ìŒ |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZQFg1RRpR11"
      },
      "source": [
        "# GPU\n",
        "`ëŸ°íƒ€ì„ -> ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½`ì„ í´ë¦­í•˜ê³  `í•˜ë“œì›¨ì–´ ê°€ì†ê¸°` ì•„ë˜ì—ì„œ `GPU`ë¥¼ ì„ íƒí•˜ë©´ Colabì—ì„œ GPU ì¥ì¹˜ë¡œ ìˆ˜ë™ ì „í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëŸ°íƒ€ì„ì„ ì „í™˜í•˜ë©´ ì»¤ë„ì´ ë‹¤ì‹œ ì‹œì‘ë˜ë¯€ë¡œ íŒ¨í‚¤ì§€ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ê¸° ì „ì— ì´ ì‘ì—…ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKvYIhDDpR12"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "USE_GPU = True\n",
        "dtype = torch.float32 # We will be using float throughout this tutorial.\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# Constant to control how frequently we print train loss.\n",
        "print_every = 100\n",
        "print('using device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4q1RwwngAJz"
      },
      "source": [
        "`using device: cuda`ê°€ ë‚˜ì˜¤ë©´ ì„±ê³µì…ë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swu-jxUigCVr"
      },
      "source": [
        "## What is 'CUDA'?\n",
        "\n",
        "\n",
        "> CUDA(\"Compute Unified Device Architecture\", ì¿ ë‹¤)ëŠ” ê·¸ë˜í”½ ì²˜ë¦¬ ì¥ì¹˜(GPU)ì—ì„œ ìˆ˜í–‰í•˜ëŠ” (ë³‘ë ¬ ì²˜ë¦¬) ì•Œê³ ë¦¬ì¦˜ì„ C í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¥¼ ë¹„ë¡¯í•œ ì‚°ì—… í‘œì¤€ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” GPGPU ê¸°ìˆ ì´ë‹¤. -Wikipedia-\n",
        "\n",
        "GPUëŠ” ì›ë˜ ê·¸ ì´ë¦„ì—ì„œë„ ì•Œ ìˆ˜ ìˆë“¯ì´ Graphic ì—°ì‚°ì„ ìœ„í•œ ì¥ì¹˜ì˜€ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ GPUê°€ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ë§¤ìš° ë¹ ë¥¸ ì†ë„ë¡œ ì²˜ë¦¬í•œë‹¤ëŠ” ì ì— ì£¼ëª©í•˜ì—¬, ì¼ë°˜ì ì¸ matrix ì—°ì‚°ì— ì‚¬ìš©ë  ìˆ˜ ìˆëŠ” GPGPU ê¸°ìˆ ì´ ì œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. NVIDAê°€ ì§€ì›í•˜ëŠ” CUDAë¥¼ í†µí•´ ê°œë°œìë“¤ì´ ì‰½ê²Œ GPU ìƒì—ì„œ ë³‘ë ¬ ì²˜ë¦¬ ì•Œê³ ë¦¬ì¦˜ì„ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤ë‹ˆë‹¤.\n",
        "\n",
        "ì§€ê¸ˆ ê³¼ì œëŠ” Colabì—ì„œ ì§„í–‰ë˜ë¯€ë¡œ íŠ¹ë³„íˆ CUDA Versionì„ ì„¤ì •í•´ ì¤„ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ê·¸ë ‡ì§€ë§Œ, ì•ìœ¼ë¡œ Local, ë˜ëŠ” Serverì—ì„œ Deep Learning ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë‹¤ ë³´ë©´ CUDA, PyTorch ë²„ì ¼ê³¼ ê´€ë ¨ëœ ì˜¤ë¥˜ë¥¼ ë§ì´ ë§ˆì£¼í•  ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ´ ë• ë‹¤ìŒê³¼ ê°™ì€ ê¸°ìˆ ì„ ê²€í† í•´ ë³´ì„¸ìš”.\n",
        "* Anaconda\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9fI9EE0pR12"
      },
      "source": [
        "# Part I. ì¤€ë¹„\n",
        "ì´ì œ CIFAR-10 ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¡œë“œí•´ ë³´ê² ìŠµë‹ˆë‹¤. ì²˜ìŒ ëª‡ ë¶„ ì •ë„ ê±¸ë¦´ ìˆ˜ ìˆì§€ë§Œ ê·¸ ì´í›„ì—ëŠ” íŒŒì¼ì´ ìºì‹œëœ ìƒíƒœë¡œ ìœ ì§€ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDBJu2TJpR13"
      },
      "outputs": [],
      "source": [
        "NUM_TRAIN = 49000\n",
        "\n",
        "# The torchvision.transforms package provides tools for preprocessing data\n",
        "# and for performing data augmentation; here we set up a transform to\n",
        "# preprocess the data by subtracting the mean RGB value and dividing by the\n",
        "# standard deviation of each RGB value; we've hardcoded the mean and std.\n",
        "transform = T.Compose([\n",
        "                T.ToTensor(),\n",
        "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "            ])\n",
        "\n",
        "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
        "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
        "# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
        "# training set into train and val sets by passing a Sampler object to the\n",
        "# DataLoader telling how it should sample from the underlying Dataset.\n",
        "cifar10_train = dset.CIFAR10('./datasets', train=True, download=True,\n",
        "                             transform=transform)\n",
        "loader_train = DataLoader(cifar10_train, batch_size=64,\n",
        "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
        "\n",
        "cifar10_val = dset.CIFAR10('./datasets', train=True, download=True,\n",
        "                           transform=transform)\n",
        "loader_val = DataLoader(cifar10_val, batch_size=64,\n",
        "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
        "\n",
        "cifar10_test = dset.CIFAR10('./datasets', train=False, download=True,\n",
        "                            transform=transform)\n",
        "loader_test = DataLoader(cifar10_test, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTVAtckopR14"
      },
      "source": [
        "# Part II. Barebones PyTorch\n",
        "PyTorchëŠ” ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ í¸ë¦¬í•˜ê²Œ ì •ì˜í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” í•˜ì´ë ˆë²¨ APIì™€ í•¨ê»˜ ì œê³µë˜ë©°, ì´ íŠœí† ë¦¬ì–¼ì˜ Part IIì—ì„œëŠ” ì´ë¥¼ ë‹¤ë£° ê²ƒì…ë‹ˆë‹¤. ì´ ì„¹ì…˜ì—ì„œëŠ” autograd engineì„ ë” ì˜ ì´í•´í•˜ê¸° ìœ„í•´ Barebones PyTorch ìš”ì†Œë¶€í„° ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì´ ì—°ìŠµì„ ë§ˆì¹˜ë©´ í•˜ì´ë ˆë²¨ ëª¨ë¸ APIë¥¼ ë” ì˜ ì´í•´í•˜ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.\n",
        "\n",
        "ë‘ ê°œì˜ ìˆ¨ê²¨ì§„ ë ˆì´ì–´ê°€ ìˆê³  CIFAR ë¶„ë¥˜ë¥¼ ìœ„í•œ biasê°€ ì—†ëŠ” ê°„ë‹¨í•œ Fully-connected ReLU ë„¤íŠ¸ì›Œí¬ë¡œ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì´ êµ¬í˜„ì€ PyTorch í…ì„œì—ì„œ ì—°ì‚°ì„ ì‚¬ìš©í•˜ì—¬ forward passë¥¼ ê³„ì‚°í•˜ê³  PyTorch autogradë¥¼ ì‚¬ìš©í•˜ì—¬ gradientë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ ì˜ˆì œ ì´í›„ì— ë” ì–´ë ¤ìš´ ë²„ì „ì„ ì‘ì„±í•  ê²ƒì´ë¯€ë¡œ ëª¨ë“  ì¤„ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
        "\n",
        "`requires_grad = True`ë¡œ PyTorch í…ì„œë¥¼ ìƒì„±í•˜ë©´ í•´ë‹¹ í…ì„œë¥¼ í¬í•¨í•˜ëŠ” ì—°ì‚°ì€ ê°’ë§Œ ê³„ì‚°í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê³„ì‚° ê·¸ë˜í”„ë¥¼ êµ¬ì¶•í•˜ì—¬ ê·¸ë˜í”„ë¥¼ í†µí•´ ì‰½ê²Œ ì—­ì „íŒŒí•˜ì—¬ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì†ì‹¤ì— ëŒ€í•œ ì¼ë¶€ í…ì„œì˜ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ xê°€ `x.requires_grad == True`ì¸ í…ì„œì¸ ê²½ìš°, ì—­ì „íŒŒ í›„ `x.grad`ëŠ” ë§ˆì§€ë§‰ì— scalar lossì— ëŒ€í•œ xì˜ ê¸°ìš¸ê¸°ë¥¼ ë³´ìœ í•˜ëŠ” ë˜ ë‹¤ë¥¸ í…ì„œê°€ ë  ê²ƒì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLO6iHpBpR15"
      },
      "source": [
        "### PyTorch Tensors: Flatten í•¨ìˆ˜\n",
        "PyTorch TensorsëŠ” ê°œë…ì ìœ¼ë¡œ nì°¨ì› ë°°ì—´ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤. nì°¨ì› ìˆ«ì ê·¸ë¦¬ë“œì´ë©°, PyTorchëŠ” nì°¨ì› ë°°ì—´ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ í…ì„œì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì‘ë™í•  ìˆ˜ ìˆëŠ” ë§ì€ í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê°„ë‹¨í•œ ì˜ˆë¡œ, ì•„ë˜ì—ì„œëŠ” ì™„ì „íˆ ì—°ê²°ëœ ì‹ ê²½ë§ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì¬êµ¬ì„±í•˜ëŠ” `flatten` í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "ì´ë¯¸ì§€ ë°ì´í„°ëŠ” ì¼ë°˜ì ìœ¼ë¡œ N x C x H x W í˜•íƒœì˜ í…ì„œì— ì €ì¥ëœë‹¤ëŠ” ì ì„ ê¸°ì–µí•˜ì„¸ìš”:\n",
        "\n",
        "* Nì€ ë°ì´í„° í¬ì¸íŠ¸ì˜ ìˆ˜ì…ë‹ˆë‹¤.\n",
        "* CëŠ” ì±„ë„ ìˆ˜ì…ë‹ˆë‹¤.\n",
        "* HëŠ” ì¤‘ê°„ íŠ¹ì§• ë§µì˜ í”½ì…€ ë‹¨ìœ„ ë†’ì´ì…ë‹ˆë‹¤.\n",
        "* WëŠ” ì¤‘ê°„ í”¼ì²˜ ë§µì˜ ë†’ì´(í”½ì…€)ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì´ëŠ” 2D convolution ê°™ì´ ì¤‘ê°„ íŠ¹ì§•ì´ ì„œë¡œ ìƒëŒ€ì ì¸ ìœ„ì¹˜ì— ëŒ€í•œ ê³µê°„ì  ì´í•´ê°€ í•„ìš”í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ë•Œ ë°ì´í„°ë¥¼ í‘œí˜„í•˜ëŠ” ë° ì í•©í•œ ë°©ë²•ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ fully connected affine layersë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•  ë•ŒëŠ” ê° ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ë‹¨ì¼ ë²¡í„°ë¡œ í‘œí˜„í•´ì•¼ í•˜ë¯€ë¡œ ë°ì´í„°ì˜ ì—¬ëŸ¬ ì±„ë„, í–‰, ì—´ì„ ë¶„ë¦¬í•˜ëŠ” ê²ƒì€ ë” ì´ìƒ ìœ ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë”°ë¼ì„œ 'flatten' ì—°ì‚°ì„ ì‚¬ìš©í•˜ì—¬ í‘œí˜„ë‹¹ `C x H x W` ê°’ì„ í•˜ë‚˜ì˜ ê¸´ ë²¡í„°ë¡œ ì¶•ì†Œí•©ë‹ˆë‹¤. ì•„ë˜ì˜ flatten í•¨ìˆ˜ëŠ” ë¨¼ì € ì£¼ì–´ì§„ ë°ì´í„° ë°°ì¹˜ì—ì„œ N, C, H, W ê°’ì„ ì½ì€ ë‹¤ìŒ í•´ë‹¹ ë°ì´í„°ì˜ 'view'ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. \"view\"ëŠ” numpyì˜ \"reshape\" ë©”ì„œë“œì™€ ìœ ì‚¬í•©ë‹ˆë‹¤. xì˜ ì°¨ì›ì„ N x ?? ë¡œ ì¬í˜•ì„±í•˜ë©°, ì—¬ê¸°ì„œ ?? ëŠ” ë¬´ì—‡ì´ë“  í—ˆìš©ë©ë‹ˆë‹¤(ì´ ê²½ìš° C x H x Wê°€ ë˜ì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUnA0EncpR15"
      },
      "outputs": [],
      "source": [
        "def flatten(x):\n",
        "    N = x.shape[0] # read in N, C, H, W\n",
        "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
        "\n",
        "def test_flatten():\n",
        "    x = torch.arange(12).view(2, 1, 3, 2)\n",
        "    print('Before flattening: ', x)\n",
        "    print('After flattening: ', flatten(x))\n",
        "\n",
        "test_flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpnPI6lVpR16"
      },
      "source": [
        "### Barebones PyTorch: Two-Layer Network\n",
        "\n",
        "ì—¬ê¸°ì—ì„œëŠ” ì´ë¯¸ì§€ ë°ì´í„° ë°°ì¹˜ì— ëŒ€í•´ ì™„ì „íˆ ì—°ê²°ëœ 2ê³„ì¸µ ReLU ë„¤íŠ¸ì›Œí¬ì˜ í¬ì›Œë“œ íŒ¨ìŠ¤ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ `two_layer_fc`ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. í¬ì›Œë“œ íŒ¨ìŠ¤ë¥¼ ì •ì˜í•œ í›„ì—ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ 0ì„ ì‹¤í–‰í•˜ì—¬ ì¶©ëŒì´ ë°œìƒí•˜ì§€ ì•ŠëŠ”ì§€, ì˜¬ë°”ë¥¸ ëª¨ì–‘ì˜ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì„œ ì½”ë“œë¥¼ ì‘ì„±í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ êµ¬í˜„ì„ ì½ê³  ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vg43S8B0pR16"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F  # useful stateless functions\n",
        "\n",
        "def two_layer_fc(x, params):\n",
        "    \"\"\"\n",
        "    A fully-connected neural networks; the architecture is:\n",
        "    NN is fully connected -> ReLU -> fully connected layer.\n",
        "    Note that this function only defines the forward pass;\n",
        "    PyTorch will take care of the backward pass for us.\n",
        "\n",
        "    The input to the network will be a minibatch of data, of shape\n",
        "    (N, d1, ..., dM) where d1 * ... * dM = D. The hidden layer will have H units,\n",
        "    and the output layer will produce scores for C classes.\n",
        "\n",
        "    Inputs:\n",
        "    - x: A PyTorch Tensor of shape (N, d1, ..., dM) giving a minibatch of\n",
        "      input data.\n",
        "    - params: A list [w1, w2] of PyTorch Tensors giving weights for the network;\n",
        "      w1 has shape (D, H) and w2 has shape (H, C).\n",
        "\n",
        "    Returns:\n",
        "    - scores: A PyTorch Tensor of shape (N, C) giving classification scores for\n",
        "      the input data x.\n",
        "    \"\"\"\n",
        "    # first we flatten the image\n",
        "    x = flatten(x)  # shape: [batch_size, C x H x W]\n",
        "\n",
        "    w1, w2 = params\n",
        "\n",
        "    # Forward pass: compute predicted y using operations on Tensors. Since w1 and\n",
        "    # w2 have requires_grad=True, operations involving these Tensors will cause\n",
        "    # PyTorch to build a computational graph, allowing automatic computation of\n",
        "    # gradients. Since we are no longer implementing the backward pass by hand we\n",
        "    # don't need to keep references to intermediate values.\n",
        "    # you can also use `.clamp(min=0)`, equivalent to F.relu()\n",
        "    x = F.relu(x.mm(w1))\n",
        "    x = x.mm(w2)\n",
        "    return x\n",
        "\n",
        "\n",
        "def two_layer_fc_test():\n",
        "    hidden_layer_size = 42\n",
        "    x = torch.zeros((64, 50), dtype=dtype)  # minibatch size 64, feature dimension 50\n",
        "    w1 = torch.zeros((50, hidden_layer_size), dtype=dtype)\n",
        "    w2 = torch.zeros((hidden_layer_size, 10), dtype=dtype)\n",
        "    scores = two_layer_fc(x, [w1, w2])\n",
        "    print(scores.size())  # you should see [64, 10]\n",
        "\n",
        "two_layer_fc_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hpfeu2JJpR17"
      },
      "source": [
        "### Barebones PyTorch: Three-Layer ConvNet\n",
        "\n",
        "ì—¬ê¸°ì„œëŠ” 3ê³„ì¸µ Convolution ë„¤íŠ¸ì›Œí¬ì˜ ìˆœë°©í–¥ íŒ¨ìŠ¤ë¥¼ ìˆ˜í–‰í•˜ëŠ” `three_layer_convnet` í•¨ìˆ˜ì˜ êµ¬í˜„ì„ ì™„ë£Œí•©ë‹ˆë‹¤. ìœ„ì™€ ê°™ì´ ë„¤íŠ¸ì›Œí¬ì— 0ì„ ì „ë‹¬í•˜ì—¬ êµ¬í˜„ì„ ì¦‰ì‹œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¥¼ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤:\n",
        "\n",
        "1. `channel_1` í•„í„°ê°€ ìˆëŠ” Convolution ë ˆì´ì–´(bias í¬í•¨), ê°ê° ëª¨ì–‘ì´ `KW1 x KH1`ì´ê³  zero padding ì´ 2ì…ë‹ˆë‹¤.\n",
        "2. ReLU nonlinearity\n",
        "3. `channel_2` í•„í„°ê°€ ìˆëŠ” Convolution ë ˆì´ì–´(bias í¬í•¨), ê° í•„í„°ì˜ ëª¨ì–‘ì´ `KW2 x KH2`ì´ê³  ì œë¡œ íŒ¨ë”©ì´ 1ì…ë‹ˆë‹¤.\n",
        "4. ReLU nonlinearity\n",
        "5. biasê°€ ìˆëŠ” Fully-connected layer, C í´ë˜ìŠ¤ì— ëŒ€í•œ ì ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "Fully-connected layer ì´í›„ì—ëŠ” **ì†Œí”„íŠ¸ë§¥ìŠ¤ í™œì„±í™”ê°€ ì—†ìŒ**ì— ìœ ì˜í•˜ì‹­ì‹œì˜¤: ì´ëŠ” PyTorchì˜ êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ì´ ì†Œí”„íŠ¸ë§¥ìŠ¤ í™œì„±í™”ë¥¼ ìˆ˜í–‰í•˜ê¸° ë•Œë¬¸ì´ë©°, ì´ ë‹¨ê³„ë¥¼ ë²ˆë“¤ë¡œ ë¬¶ìœ¼ë©´ ê³„ì‚°ì´ ë” íš¨ìœ¨ì ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "**íŒíŠ¸**: Convolutionsì— ëŒ€í•´: http://pytorch.org/docs/stable/nn.html#torch.nn.functional.conv2d; convolutional filters ëª¨ì–‘ì— ì£¼ì˜í•´ ì£¼ì„¸ìš”!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECDdAX4GpR18"
      },
      "outputs": [],
      "source": [
        "def three_layer_convnet(x, params):\n",
        "    \"\"\"\n",
        "    Performs the forward pass of a three-layer convolutional network with the\n",
        "    architecture defined above.\n",
        "\n",
        "    Inputs:\n",
        "    - x: A PyTorch Tensor of shape (N, 3, H, W) giving a minibatch of images\n",
        "    - params: A list of PyTorch Tensors giving the weights and biases for the\n",
        "      network; should contain the following:\n",
        "      - conv_w1: PyTorch Tensor of shape (channel_1, 3, KH1, KW1) giving weights\n",
        "        for the first convolutional layer\n",
        "      - conv_b1: PyTorch Tensor of shape (channel_1,) giving biases for the first\n",
        "        convolutional layer\n",
        "      - conv_w2: PyTorch Tensor of shape (channel_2, channel_1, KH2, KW2) giving\n",
        "        weights for the second convolutional layer\n",
        "      - conv_b2: PyTorch Tensor of shape (channel_2,) giving biases for the second\n",
        "        convolutional layer\n",
        "      - fc_w: PyTorch Tensor giving weights for the fully-connected layer. Can you\n",
        "        figure out what the shape should be?\n",
        "      - fc_b: PyTorch Tensor giving biases for the fully-connected layer. Can you\n",
        "        figure out what the shape should be?\n",
        "\n",
        "    Returns:\n",
        "    - scores: PyTorch Tensor of shape (N, C) giving classification scores for x\n",
        "    \"\"\"\n",
        "    conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n",
        "    scores = None\n",
        "    ################################################################################\n",
        "    # TODO: Implement the forward pass for the three-layer ConvNet.                #\n",
        "    ################################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    pass\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ################################################################################\n",
        "    #                                 END OF YOUR CODE                             #\n",
        "    ################################################################################\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6hBYahWpR18"
      },
      "source": [
        "ìœ„ì—ì„œ ConvNetì˜ í¬ì›Œë“œ íŒ¨ìŠ¤ë¥¼ ì •ì˜í•œ í›„ ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì—¬ êµ¬í˜„ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì´ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ë©´ ì ìˆ˜ëŠ” (64, 10) ëª¨ì–‘ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "barebones_output_shape"
      },
      "outputs": [],
      "source": [
        "def three_layer_convnet_test():\n",
        "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
        "\n",
        "    conv_w1 = torch.zeros((6, 3, 5, 5), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n",
        "    conv_b1 = torch.zeros((6,))  # out_channel\n",
        "    conv_w2 = torch.zeros((9, 6, 3, 3), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n",
        "    conv_b2 = torch.zeros((9,))  # out_channel\n",
        "\n",
        "    # you must calculate the shape of the tensor after two conv layers, before the fully-connected layer\n",
        "    fc_w = torch.zeros((9 * 32 * 32, 10))\n",
        "    fc_b = torch.zeros(10)\n",
        "\n",
        "    scores = three_layer_convnet(x, [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b])\n",
        "    print(scores.size())  # you should see [64, 10]\n",
        "three_layer_convnet_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jxzynJspR19"
      },
      "source": [
        "### Barebones PyTorch: Initialization\n",
        "ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ì´ˆê¸°í™”í•˜ëŠ” ëª‡ ê°€ì§€ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë¥¼ ì‘ì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "- `random_weight(shape)`ëŠ” Kaiming normalization ë°©ë²•ìœ¼ë¡œ ê°€ì¤‘ì¹˜ í…ì„œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
        "- `zero_weight(shape)`ëŠ” ëª¨ë“  0ìœ¼ë¡œ ê°€ì¤‘ì¹˜ í…ì„œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ë°”ì´ì–´ìŠ¤ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¸ìŠ¤í„´ìŠ¤í™”í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "`random_weight` í•¨ìˆ˜ëŠ” Kaiming normal initialization ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:\n",
        "\n",
        "He et al, *Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification*, ICCV 2015, https://arxiv.org/abs/1502.01852"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXkgnTzMpR19"
      },
      "outputs": [],
      "source": [
        "def random_weight(shape):\n",
        "    \"\"\"\n",
        "    Create random Tensors for weights; setting requires_grad=True means that we\n",
        "    want to compute gradients for these Tensors during the backward pass.\n",
        "    We use Kaiming normalization: sqrt(2 / fan_in)\n",
        "    \"\"\"\n",
        "    if len(shape) == 2:  # FC weight\n",
        "        fan_in = shape[0]\n",
        "    else:\n",
        "        fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW]\n",
        "    # randn is standard normal distribution generator.\n",
        "    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n",
        "    w.requires_grad = True\n",
        "    return w\n",
        "\n",
        "def zero_weight(shape):\n",
        "    return torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "# create a weight of shape [3 x 5]\n",
        "# you should see the type `torch.cuda.FloatTensor` if you use GPU.\n",
        "# Otherwise it should be `torch.FloatTensor`\n",
        "random_weight((3, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z1t3y6YpR19"
      },
      "source": [
        "### Barebones PyTorch: Check Accuracy\n",
        "ëª¨ë¸ì„ í›ˆë ¨í•  ë•Œ ë‹¤ìŒ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ë˜ëŠ” ê²€ì¦ ì„¸íŠ¸ì—ì„œ ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì •í™•ë„ë¥¼ í™•ì¸í•  ë•Œ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•  í•„ìš”ê°€ ì—†ìœ¼ë¯€ë¡œ ì ìˆ˜ë¥¼ ê³„ì‚°í•  ë•Œ PyTorchê°€ ê³„ì‚° ê·¸ë˜í”„ë¥¼ ë§Œë“¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ê·¸ë˜í”„ê°€ ìƒì„±ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ `torch.no_grad()` context managerì—ì„œ ê³„ì‚° ë²”ìœ„ë¥¼ ì§€ì •í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jre5tpX2pR1-"
      },
      "outputs": [],
      "source": [
        "def check_accuracy_part2(loader, model_fn, params):\n",
        "    \"\"\"\n",
        "    Check the accuracy of a classification model.\n",
        "\n",
        "    Inputs:\n",
        "    - loader: A DataLoader for the data split we want to check\n",
        "    - model_fn: A function that performs the forward pass of the model,\n",
        "      with the signature scores = model_fn(x, params)\n",
        "    - params: List of PyTorch Tensors giving parameters of the model\n",
        "\n",
        "    Returns: Nothing, but prints the accuracy of the model\n",
        "    \"\"\"\n",
        "    split = 'val' if loader.dataset.train else 'test'\n",
        "    print('Checking accuracy on the %s set' % split)\n",
        "    num_correct, num_samples = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.int64)\n",
        "            scores = model_fn(x, params)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwNMOvc7pR1-"
      },
      "source": [
        "### BareBones PyTorch: Training Loop\n",
        "ì´ì œ ë„¤íŠ¸ì›Œí¬ë¥¼ í›ˆë ¨í•˜ê¸° ìœ„í•œ basic training loopë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. momentum ì—†ì´ Stochastic gradient descentë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•  ê²ƒì…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” `torch.functional.cross_entropy`ë¥¼ ì‚¬ìš©í•˜ì—¬ lossë¥¼ ê³„ì‚°í•  ê²ƒì…ë‹ˆë‹¤(http://pytorch.org/docs/stable/nn.html#cross-entropy).\n",
        "\n",
        "training loopëŠ” ì‹ ê²½ë§ í•¨ìˆ˜, ì´ˆê¸°í™”ëœ ë§¤ê°œë³€ìˆ˜ ëª©ë¡(ì˜ˆì œì—ì„œëŠ” `[w1, w2]`), í•™ìŠµ ì†ë„ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fyt2Boy_pR1-"
      },
      "outputs": [],
      "source": [
        "def train_part2(model_fn, params, learning_rate):\n",
        "    \"\"\"\n",
        "    Train a model on CIFAR-10.\n",
        "\n",
        "    Inputs:\n",
        "    - model_fn: A Python function that performs the forward pass of the model.\n",
        "      It should have the signature scores = model_fn(x, params) where x is a\n",
        "      PyTorch Tensor of image data, params is a list of PyTorch Tensors giving\n",
        "      model weights, and scores is a PyTorch Tensor of shape (N, C) giving\n",
        "      scores for the elements in x.\n",
        "    - params: List of PyTorch Tensors giving weights for the model\n",
        "    - learning_rate: Python scalar giving the learning rate to use for SGD\n",
        "\n",
        "    Returns: Nothing\n",
        "    \"\"\"\n",
        "    for t, (x, y) in enumerate(loader_train):\n",
        "        # Move the data to the proper device (GPU or CPU)\n",
        "        x = x.to(device=device, dtype=dtype)\n",
        "        y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "        # Forward pass: compute scores and loss\n",
        "        scores = model_fn(x, params)\n",
        "        loss = F.cross_entropy(scores, y)\n",
        "\n",
        "        # Backward pass: PyTorch figures out which Tensors in the computational\n",
        "        # graph has requires_grad=True and uses backpropagation to compute the\n",
        "        # gradient of the loss with respect to these Tensors, and stores the\n",
        "        # gradients in the .grad attribute of each Tensor.\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters. We don't want to backpropagate through the\n",
        "        # parameter updates, so we scope the updates under a torch.no_grad()\n",
        "        # context manager to prevent a computational graph from being built.\n",
        "        with torch.no_grad():\n",
        "            for w in params:\n",
        "                w -= learning_rate * w.grad\n",
        "\n",
        "                # Manually zero the gradients after running the backward pass\n",
        "                w.grad.zero_()\n",
        "\n",
        "        if t % print_every == 0:\n",
        "            print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
        "            check_accuracy_part2(loader_val, model_fn, params)\n",
        "            print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhZfY1PzpR1_"
      },
      "source": [
        "### BareBones PyTorch: Train a Two-Layer Network\n",
        "ì´ì œ training loopë¥¼ ì‹¤í–‰í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. fully connected weightsì¸ `w1`ê³¼ `w2`ì— ëŒ€í•œ Tensorë¥¼ ëª…ì‹œì ìœ¼ë¡œ í• ë‹¹í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "CIFARì˜ ê° minibatchì—ëŠ” 64ê°œì˜ ì˜ˆê°€ ìˆìœ¼ë¯€ë¡œ í…ì„œ ëª¨ì–‘ì€ `[64, 3, 32, 32]`ì…ë‹ˆë‹¤.\n",
        "\n",
        "flatten í›„ `x` ëª¨ì–‘ì€ `[64, 3 * 32 * 32]`ê°€ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ê²ƒì´ `w1`ì˜ ì²« ë²ˆì§¸ ì°¨ì› í¬ê¸°ê°€ ë©ë‹ˆë‹¤.\n",
        "`w1`ì˜ ë‘ ë²ˆì§¸ ì°¨ì›ì€ hidden layer sizeì´ë©°, ì´ëŠ” ë˜í•œ `w2`ì˜ ì²« ë²ˆì§¸ ì°¨ì›ì´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "ë§ˆì§€ë§‰ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ì˜ ì¶œë ¥ì€ 10ê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” 10ì°¨ì› ë²¡í„°ì…ë‹ˆë‹¤.\n",
        "\n",
        "hyperparameterë¥¼ ì¡°ì •í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ í•œ íšŒê¸° ë™ì•ˆ í›ˆë ¨í•œ í›„ì—ëŠ” 40% ì´ìƒì˜ ì •í™•ë„ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVhigckkpR1_"
      },
      "outputs": [],
      "source": [
        "hidden_layer_size = 4000\n",
        "learning_rate = 1e-2\n",
        "\n",
        "w1 = random_weight((3 * 32 * 32, hidden_layer_size))\n",
        "w2 = random_weight((hidden_layer_size, 10))\n",
        "\n",
        "train_part2(two_layer_fc, [w1, w2], learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qHT93KFpR1_"
      },
      "source": [
        "### BareBones PyTorch: Training a ConvNet\n",
        "\n",
        "ì•„ë˜ì—ì„œëŠ” ìœ„ì—ì„œ ì •ì˜í•œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ CIFARì—ì„œ 3ê³„ì¸µ Convolutional networkë¥¼ í›ˆë ¨í•´ì•¼ í•©ë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ì˜ ì•„í‚¤í…ì²˜ëŠ” ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:\n",
        "\n",
        "1. 32ê°œì˜ 5x5 í•„í„°ê°€ ìˆëŠ” ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´(ë°”ì´ì–´ìŠ¤ í¬í•¨), ì œë¡œ íŒ¨ë”©ì€ 2ì…ë‹ˆë‹¤.\n",
        "2. ReLU\n",
        "3. 16ê°œì˜ 3x3 í•„í„°ê°€ ìˆëŠ” ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´(ë°”ì´ì–´ìŠ¤ í¬í•¨), ì œë¡œ íŒ¨ë”© 1\n",
        "4. ReLU\n",
        "5. 10ê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•œ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ ì™„ì „ ì—°ê²° ë ˆì´ì–´(ë°”ì´ì–´ìŠ¤ í¬í•¨)\n",
        "\n",
        "ìœ„ì—ì„œ ì •ì˜í•œ `random_weight` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ì´ˆê¸°í™”í•´ì•¼ í•˜ë©°, ìœ„ì˜ `zero_weight` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°”ì´ì–´ìŠ¤ ë²¡í„°ë¥¼ ì´ˆê¸°í™”í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ ëª¨ë“  ê²ƒì´ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ë©´ í•œ ì—í¬í¬ í›„ì— 42% ì´ìƒì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "barebones_accuracy"
      },
      "outputs": [],
      "source": [
        "learning_rate = 3e-3\n",
        "\n",
        "channel_1 = 32\n",
        "channel_2 = 16\n",
        "\n",
        "conv_w1 = None\n",
        "conv_b1 = None\n",
        "conv_w2 = None\n",
        "conv_b2 = None\n",
        "fc_w = None\n",
        "fc_b = None\n",
        "\n",
        "################################################################################\n",
        "# TODO: Initialize the parameters of a three-layer ConvNet.                    #\n",
        "################################################################################\n",
        "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "'''\n",
        "    Inputs:\n",
        "    - x: A PyTorch Tensor of shape (N, 3, H, W) giving a minibatch of images\n",
        "    - params: A list of PyTorch Tensors giving the weights and biases for the\n",
        "      network; should contain the following:\n",
        "      - conv_w1: PyTorch Tensor of shape (channel_1, 3, KH1, KW1) giving weights\n",
        "        for the first convolutional layer\n",
        "      - conv_b1: PyTorch Tensor of shape (channel_1,) giving biases for the first\n",
        "        convolutional layer\n",
        "      - conv_w2: PyTorch Tensor of shape (channel_2, channel_1, KH2, KW2) giving\n",
        "        weights for the second convolutional layer\n",
        "      - conv_b2: PyTorch Tensor of shape (channel_2,) giving biases for the second\n",
        "        convolutional layer\n",
        "      - fc_w: PyTorch Tensor giving weights for the fully-connected layer. Can you\n",
        "        figure out what the shape should be?\n",
        "      - fc_b: PyTorch Tensor giving biases for the fully-connected layer. Can you\n",
        "        figure out what the shape should be?\n",
        "'''\n",
        "\n",
        "pass\n",
        "\n",
        "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "################################################################################\n",
        "#                                 END OF YOUR CODE                             #\n",
        "################################################################################\n",
        "\n",
        "params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n",
        "train_part2(three_layer_convnet, params, learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpzU23oApR2A"
      },
      "source": [
        "# Part III. PyTorch Module API\n",
        "\n",
        "Barebone PyTorchì—ì„œëŠ” ëª¨ë“  Parameter tensorsë¥¼ ìˆ˜ì‘ì—…ìœ¼ë¡œ ì¶”ì í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” ëª‡ ê°œì˜ í…ì„œê°€ ìˆëŠ” ì†Œê·œëª¨ ë„¤íŠ¸ì›Œí¬ì—ì„œëŠ” ê´œì°®ì§€ë§Œ, ëŒ€ê·œëª¨ ë„¤íŠ¸ì›Œí¬ì—ì„œ ìˆ˜ì‹­ ë˜ëŠ” ìˆ˜ë°± ê°œì˜ í…ì„œë¥¼ ì¶”ì í•˜ëŠ” ê²ƒì€ ë§¤ìš° ë¶ˆí¸í•˜ê³  ì˜¤ë¥˜ê°€ ë°œìƒí•˜ê¸° ì‰½ìŠµë‹ˆë‹¤.\n",
        "\n",
        "PyTorchëŠ” ì„ì˜ì˜ ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ë¥¼ ì •ì˜í•˜ëŠ” ë™ì‹œì— í•™ìŠµ ê°€ëŠ¥í•œ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì í•  ìˆ˜ ìˆë„ë¡ `nn.Module` APIë¥¼ ì œê³µí•©ë‹ˆë‹¤. Part IIì—ì„œëŠ” SGDë¥¼ ì§ì ‘ êµ¬í˜„í•´ ë³´ì•˜ìŠµë‹ˆë‹¤. PyTorchëŠ” ë˜í•œ RMSProp, Adagrad, Adamê³¼ ê°™ì€ ëª¨ë“  ì¼ë°˜ì ì¸ Optimizerë¥¼ êµ¬í˜„í•˜ëŠ” `torch.optim` íŒ¨í‚¤ì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì‹¬ì§€ì–´ L-BFGSì™€ ê°™ì€ ëŒ€ëµì ì¸ 2ì°¨ ë°©ë²•ë„ ì§€ì›í•©ë‹ˆë‹¤! ê° ì˜µí‹°ë§ˆì´ì €ì˜ ì •í™•í•œ ì‚¬ì–‘ì€ [ë¬¸ì„œ](http://pytorch.org/docs/master/optim.html)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.\n",
        "\n",
        "ëª¨ë“ˆ APIë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì•„ë˜ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:\n",
        "\n",
        "1. ì„œë¸Œí´ë˜ìŠ¤ `nn.Module`. ë„¤íŠ¸ì›Œí¬ í´ë˜ìŠ¤ì— `TwoLayerFC`ì™€ ê°™ì€ ì§ê´€ì ì¸ ì´ë¦„ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
        "\n",
        "2. ìƒì„±ì `__init__()`ì—ì„œ í•„ìš”í•œ ëª¨ë“  ë ˆì´ì–´ë¥¼ í´ë˜ìŠ¤ ì†ì„±ìœ¼ë¡œ ì •ì˜í•©ë‹ˆë‹¤. `nn.Linear` ë° `nn.Conv2d`ì™€ ê°™ì€ ë ˆì´ì–´ ê°ì²´ëŠ” ê·¸ ìì²´ë¡œ `nn.Module` ì„œë¸Œí´ë˜ìŠ¤ì´ë©° í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•˜ë¯€ë¡œ ì›ì‹œ í…ì„œë¥¼ ì§ì ‘ ì¸ìŠ¤í„´ìŠ¤í™”í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. `nn.Module`ì´ ì´ëŸ¬í•œ ë‚´ë¶€ íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì í•©ë‹ˆë‹¤. ìˆ˜ì‹­ ê°œì˜ ë‚´ì¥ ë ˆì´ì–´ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ë ¤ë©´ [ë¬¸ì„œ](http://pytorch.org/docs/master/nn.html)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”. **ê²½ê³ **: `super().__init__()`ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ëŠ” ê²ƒì„ ìŠì§€ ë§ˆì„¸ìš”!\n",
        "\n",
        "3. `forward()` ë©”ì„œë“œì—ì„œ ë„¤íŠ¸ì›Œí¬ì˜ *ì—°ê²°ì„±*ì„ ì •ì˜í•©ë‹ˆë‹¤. í…ì„œë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê³  \"ë³€í™˜ëœ\" í…ì„œë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œë¡œ `__init__`ì— ì •ì˜ëœ ì†ì„±ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. `forward()`ì—ì„œ í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ê°€ ìˆëŠ” ìƒˆ ë ˆì´ì–´ë¥¼ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”! ëª¨ë“  ë§¤ê°œë³€ìˆ˜ëŠ” `__init__`ì—ì„œ ë¯¸ë¦¬ ì„ ì–¸í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "ëª¨ë“ˆ ì„œë¸Œí´ë˜ìŠ¤ë¥¼ ì •ì˜í•œ í›„ì—ëŠ” ê°ì²´ë¡œ ì¸ìŠ¤í„´ìŠ¤í™”í•˜ì—¬ Part IIì˜ NN ì „ë‹¬ í•¨ìˆ˜ì²˜ëŸ¼ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "### Module API: Two-Layer Network\n",
        "ë‹¤ìŒì€ fully connected 2ê³„ì¸µ ë„¤íŠ¸ì›Œí¬ì˜ êµ¬ì²´ì ì¸ ì˜ˆì…ë‹ˆë‹¤:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSrvts7LpR2A"
      },
      "outputs": [],
      "source": [
        "class TwoLayerFC(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super().__init__()\n",
        "        # assign layer objects to class attributes\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        # nn.init package contains convenient initialization methods\n",
        "        # http://pytorch.org/docs/master/nn.html#torch-nn-init\n",
        "        nn.init.kaiming_normal_(self.fc1.weight)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "        nn.init.kaiming_normal_(self.fc2.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # forward always defines connectivity\n",
        "        x = flatten(x)\n",
        "        scores = self.fc2(F.relu(self.fc1(x)))\n",
        "        return scores\n",
        "\n",
        "def test_TwoLayerFC():\n",
        "    input_size = 50\n",
        "    x = torch.zeros((64, input_size), dtype=dtype)  # minibatch size 64, feature dimension 50\n",
        "    model = TwoLayerFC(input_size, 42, 10)\n",
        "    scores = model(x)\n",
        "    print(scores.size())  # you should see [64, 10]\n",
        "test_TwoLayerFC()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTbHlNclpR2A"
      },
      "source": [
        "### Module API: Three-Layer ConvNet\n",
        "ì´ì œ ì™„ì „íˆ ì—°ê²°ëœ ë ˆì´ì–´ì— ì´ì–´ 3ê³„ì¸µ ConvNetì„ êµ¬í˜„í•  ì°¨ë¡€ì…ë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ëŠ” íŒŒíŠ¸ IIì™€ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤:\n",
        "\n",
        "1. zero-paddingì´ 2ì¸ `channel_1` 5x5 í•„í„°ê°€ ìˆëŠ” ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´\n",
        "2. ReLU\n",
        "3. `channel_2` 3x3 í•„í„°ê°€ ìˆëŠ” Convolution Layer, zero-padding 1\n",
        "4. ReLU\n",
        "5. `num_classes` í´ë˜ìŠ¤ì— ì™„ì „íˆ ì—°ê²°ëœ ë ˆì´ì–´\n",
        "\n",
        "Kaiming normal initialize ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ì´ˆê¸°í™”í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "**HINT**: http://pytorch.org/docs/stable/nn.html#conv2d\n",
        "\n",
        "3ê³„ì¸µ ConvNetì„ êµ¬í˜„í•œ í›„ `test_ThreeLayerConvNet` í•¨ìˆ˜ê°€ êµ¬í˜„ì„ ì‹¤í–‰í•˜ë©´ ì¶œë ¥ ì ìˆ˜ì˜ ëª¨ì–‘ì— ëŒ€í•´ `(64, 10)`ì´ ì¶œë ¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "module_output_shape"
      },
      "outputs": [],
      "source": [
        "class ThreeLayerConvNet(nn.Module):\n",
        "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
        "        super().__init__()\n",
        "        ########################################################################\n",
        "        # TODO: Set up the layers you need for a three-layer ConvNet with the  #\n",
        "        # architecture defined above.                                          #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        pass\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                          END OF YOUR CODE                            #\n",
        "        ########################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        scores = None\n",
        "        ########################################################################\n",
        "        # TODO: Implement the forward function for a 3-layer ConvNet. you      #\n",
        "        # should use the layers you defined in __init__ and specify the        #\n",
        "        # connectivity of those layers in forward()                            #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        pass\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "        return scores\n",
        "\n",
        "\n",
        "def test_ThreeLayerConvNet():\n",
        "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
        "    model = ThreeLayerConvNet(in_channel=3, channel_1=12, channel_2=8, num_classes=10)\n",
        "    scores = model(x)\n",
        "    print(scores.size())  # you should see [64, 10]\n",
        "test_ThreeLayerConvNet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3CDip-7pR2B"
      },
      "source": [
        "### Module API: Check Accuracy\n",
        "ê²€ì¦ ë˜ëŠ” í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ê°€ ì£¼ì–´ì§€ë©´ ì‹ ê²½ë§ì˜ ë¶„ë¥˜ ì •í™•ë„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì´ ë²„ì „ì€ Part IIì˜ ë²„ì „ê³¼ ì•½ê°„ ë‹¤ë¦…ë‹ˆë‹¤. ë” ì´ìƒ ë§¤ê°œ ë³€ìˆ˜ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì „ë‹¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PYAZQ1DpR2B"
      },
      "outputs": [],
      "source": [
        "def check_accuracy_part34(loader, model):\n",
        "    if loader.dataset.train:\n",
        "        print('Checking accuracy on validation set')\n",
        "    else:\n",
        "        print('Checking accuracy on test set')\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            scores = model(x)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb6341vOpR2B"
      },
      "source": [
        "### Module API: Training Loop\n",
        "ë˜í•œ ì•½ê°„ ë‹¤ë¥¸ training loopë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ê°€ì¤‘ì¹˜ ê°’ì„ ì§ì ‘ ì—…ë°ì´íŠ¸í•˜ëŠ” ëŒ€ì‹ , Optimization ì•Œê³ ë¦¬ì¦˜ì˜ ê°œë…ì„ ì¶”ìƒí™”í•˜ê³  ì‹ ê²½ë§ ìµœì í™”ì— ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ëŒ€ë¶€ë¶„ì˜ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ì„ ì œê³µí•˜ëŠ” `torch.optim` íŒ¨í‚¤ì§€ì˜ Optimizer ê°ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lY-B6AXbpR2B"
      },
      "outputs": [],
      "source": [
        "def train_part34(model, optimizer, epochs=1):\n",
        "    \"\"\"\n",
        "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
        "\n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "\n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    for e in range(epochs):\n",
        "        for t, (x, y) in enumerate(loader_train):\n",
        "            model.train()  # put model to training mode\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "            scores = model(x)\n",
        "            loss = F.cross_entropy(scores, y)\n",
        "\n",
        "            # Zero out all of the gradients for the variables which the optimizer\n",
        "            # will update.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # This is the backwards pass: compute the gradient of the loss with\n",
        "            # respect to each  parameter of the model.\n",
        "            loss.backward()\n",
        "\n",
        "            # Actually update the parameters of the model using the gradients\n",
        "            # computed by the backwards pass.\n",
        "            optimizer.step()\n",
        "\n",
        "            if t % print_every == 0:\n",
        "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
        "                check_accuracy_part34(loader_val, model)\n",
        "                print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMFEsm-OpR2C"
      },
      "source": [
        "### Module API: Train a Two-Layer Network\n",
        "ì´ì œ training loopë¥¼ ì‹¤í–‰í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. Part IIì™€ ë‹¬ë¦¬ ì´ë²ˆì—ëŠ” Parameter tensorsë¥¼ ë” ì´ìƒ ëª…ì‹œì ìœ¼ë¡œ í• ë‹¹í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì…ë ¥ í¬ê¸°, ìˆ¨ê²¨ì§„ ë ˆì´ì–´ í¬ê¸°, í´ë˜ìŠ¤ ìˆ˜(ì¦‰, ì¶œë ¥ í¬ê¸°)ë¥¼ `TwoLayerFC`ì˜ ìƒì„±ìì— ì „ë‹¬í•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "ë˜í•œ `TwoLayerFC` ë‚´ì—ì„œ í•™ìŠµ ê°€ëŠ¥í•œ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì í•˜ëŠ” ì˜µí‹°ë§ˆì´ì €ë¥¼ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ, í•œ epoch ë™ì•ˆ í•™ìŠµí•œ í›„ 40% ì´ìƒì˜ ëª¨ë¸ ì •í™•ë„ë¥¼ ë³¼ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCwaZfJTpR2C"
      },
      "outputs": [],
      "source": [
        "hidden_layer_size = 4000\n",
        "learning_rate = 1e-2\n",
        "model = TwoLayerFC(3 * 32 * 32, hidden_layer_size, 10)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_part34(model, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvnHTm_MpR2C"
      },
      "source": [
        "### Module API: Train a Three-Layer ConvNet\n",
        "ì´ì œ Module APIë¥¼ ì‚¬ìš©í•˜ì—¬ CIFARì—ì„œ 3ê³„ì¸µ ConvNetì„ í›ˆë ¨í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” 2ê³„ì¸µ ë„¤íŠ¸ì›Œí¬ í›ˆë ¨ê³¼ ë§¤ìš° ìœ ì‚¬í•˜ê²Œ ë³´ì¼ ê²ƒì…ë‹ˆë‹¤! í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ, í•œ íšŒê¸° ë™ì•ˆ í›ˆë ¨í•œ í›„ 45% ì´ìƒì„ ë‹¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "Momentumì´ ì—†ëŠ” Stochastic gradient descentë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "module_accuracy"
      },
      "outputs": [],
      "source": [
        "learning_rate = 3e-3\n",
        "channel_1 = 32\n",
        "channel_2 = 16\n",
        "\n",
        "model = None\n",
        "optimizer = None\n",
        "################################################################################\n",
        "# TODO: Instantiate your ThreeLayerConvNet model and a corresponding optimizer #\n",
        "################################################################################\n",
        "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "pass\n",
        "\n",
        "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "################################################################################\n",
        "#                                 END OF YOUR CODE                             #\n",
        "################################################################################\n",
        "\n",
        "train_part34(model, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsFqIP43pR2D"
      },
      "source": [
        "# Part IV. PyTorch Sequential API\n",
        "\n",
        "Part IIIì—ì„œëŠ” ì„ì˜ì˜ í•™ìŠµ ê°€ëŠ¥í•œ ë ˆì´ì–´ì™€ ê·¸ ì—°ê²°ì„±ì„ ì •ì˜í•  ìˆ˜ ìˆëŠ” PyTorch ëª¨ë“ˆ APIë¥¼ ì†Œê°œí–ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "Feed forward layersê³¼ ê°™ì€ ê°„ë‹¨í•œ ëª¨ë¸ì˜ ê²½ìš°, `nn.Module` ì„œë¸Œí´ë˜ìŠ¤ë¥¼ ìƒì„±í•˜ê³ , `__init__`ì—ì„œ í´ë˜ìŠ¤ ì†ì„±ì— ë ˆì´ì–´ë¥¼ í• ë‹¹í•˜ê³ , `forward()`ì—ì„œ ê° ë ˆì´ì–´ë¥¼ í•˜ë‚˜ì”© í˜¸ì¶œí•˜ëŠ” 3ë‹¨ê³„ë¥¼ ê±°ì³ì•¼ í•©ë‹ˆë‹¤. ë” í¸ë¦¬í•œ ë°©ë²•ì´ ìˆì„ê¹Œìš”?\n",
        "\n",
        "ë‹¤í–‰íˆë„ PyTorchì—ì„œëŠ” ìœ„ì˜ ë‹¨ê³„ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹œ `nn.Sequential`ì´ë¼ëŠ” ì»¨í…Œì´ë„ˆ ëª¨ë“ˆì„ ì œê³µí•©ë‹ˆë‹¤. feed forward stacksë³´ë‹¤ ë” ë³µì¡í•œ topologyë¥¼ ì§€ì •í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— `nn.Module`ë§Œí¼ ìœ ì—°í•˜ì§€ëŠ” ì•Šì§€ë§Œ, ë§ì€ ì‚¬ìš© ì‚¬ë¡€ì— ì¶©ë¶„í•©ë‹ˆë‹¤.\n",
        "\n",
        "### Sequential API: 2ê³„ì¸µ ë„¤íŠ¸ì›Œí¬\n",
        "`nn.Sequential`ì„ ì‚¬ìš©í•˜ì—¬ 2ê³„ì¸µ fully connected ë„¤íŠ¸ì›Œí¬ ì˜ˆì œë¥¼ ë‹¤ì‹œ ì‘ì„±í•˜ê³  ìœ„ì—ì„œ ì •ì˜í•œ training loopë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë ˆì´ë‹í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë´…ì‹œë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì„œë„ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ, í•œ ë²ˆì˜ í›ˆë ¨ í›„ì—ëŠ” 40% ì´ìƒì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTN-_2OmpR2D"
      },
      "outputs": [],
      "source": [
        "# We need to wrap `flatten` function in a module in order to stack it\n",
        "# in nn.Sequential\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return flatten(x)\n",
        "\n",
        "hidden_layer_size = 4000\n",
        "learning_rate = 1e-2\n",
        "\n",
        "model = nn.Sequential(\n",
        "    Flatten(),\n",
        "    nn.Linear(3 * 32 * 32, hidden_layer_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_layer_size, 10),\n",
        ")\n",
        "\n",
        "# you can use Nesterov momentum in optim.SGD\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
        "                     momentum=0.9, nesterov=True)\n",
        "\n",
        "train_part34(model, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ppx-dXtZpR2D"
      },
      "source": [
        "### Sequential API: Three-Layer ConvNet\n",
        "ì—¬ê¸°ì„œëŠ” `nn.Sequential`ì„ ì‚¬ìš©í•˜ì—¬ Part IIIì—ì„œ ì‚¬ìš©í•œ ê²ƒê³¼ ë™ì¼í•œ ì•„í‚¤í…ì²˜ë¡œ 3ê³„ì¸µ ConvNetì„ ì •ì˜í•˜ê³  í›ˆë ¨í•´ì•¼ í•©ë‹ˆë‹¤:\n",
        "\n",
        "1. 32ê°œì˜ 5x5 í•„í„°ê°€ ìˆëŠ” Convolution ë ˆì´ì–´(ë°”ì´ì–´ìŠ¤ í¬í•¨), zero-paddingì€ 2ì…ë‹ˆë‹¤.\n",
        "2. ReLU\n",
        "3. 16ê°œì˜ 3x3 í•„í„°ê°€ ìˆëŠ” Convolution ë ˆì´ì–´(ë°”ì´ì–´ìŠ¤ í¬í•¨), zero-padding 1\n",
        "4. ReLU\n",
        "5. 10ê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•œ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ  fully-connected layer(ë°”ì´ì–´ìŠ¤ í¬í•¨)\n",
        "\n",
        "ê¸°ë³¸ PyTorch ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "Nesterov momentum 0.9ì˜ í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ìµœì í™”í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "ë‹¤ì‹œ ë§í•˜ì§€ë§Œ, í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ í•œ ë²ˆì˜ í›ˆë ¨ í›„ì—ëŠ” 55% ì´ìƒì˜ ì •í™•ë„ë¥¼ ë³¼ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CP6-UsQtzMeI"
      },
      "outputs": [],
      "source": [
        "channel_1 = 32\n",
        "channel_2 = 16\n",
        "learning_rate = 1e-2\n",
        "\n",
        "model = None\n",
        "optimizer = None\n",
        "\n",
        "################################################################################\n",
        "# TODO: Rewrite the 2-layer ConvNet with bias from Part III with the           #\n",
        "# Sequential API.                                                              #\n",
        "################################################################################\n",
        "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "pass\n",
        "\n",
        "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "################################################################################\n",
        "#                                 END OF YOUR CODE                             #\n",
        "################################################################################\n",
        "\n",
        "train_part34(model, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AhsbVrNoPt7"
      },
      "source": [
        "# Let's do this! - Reimplement AlexNet\n",
        "ì´ì œ PyTorchì˜ ê¸°ë³¸ì ì¸ ì‚¬ìš©ë²•ì„ ëª¨ë‘ ë°°ì›Œ ë´¤ìŠµë‹ˆë‹¤. ì§€ê¸ˆê¹Œì§€ ë°°ì› ë˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ Deep Into Deep ìˆ˜ì—… ì¤‘ì— ë‹¤ë£¨ì—ˆë˜ ëª¨ë¸ ì¤‘ í•˜ë‚˜ì¸ [AlexNet](https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)ì„ ì¬êµ¬í˜„í•´ ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdF9qsXnLi_W"
      },
      "source": [
        "## AlexNet Architecture\n",
        "AlexNetì˜ ì „ì²´ì ì¸ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gl7KqYljPjbO"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "images = './notebook_images/AlexNet_Architecture.png'\n",
        "image = cv2.imread(images)\n",
        "cv2_imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kESoCsqDQuLX"
      },
      "source": [
        "## êµ¬í˜„ ì„¸ë¶€ì‚¬í•­\n",
        "ì´ ê·¸ë¦¼ì„ ë°”íƒ•ìœ¼ë¡œ AlexNetì„ ì¬êµ¬í˜„ í•´ ë´…ì‹œë‹¤. ê·¸ëŸ¬ê¸° ìœ„í•´ì„œ ëª‡ ê°€ì§€ ì•Œê³  ë„˜ì–´ê°€ì•¼í•  ë¶€ë¶„ì´ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "AlexNetì˜ Input DataëŠ” ì›ë˜ 3x227x227ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ìš°ë¦¬ëŠ” ì§€ê¸ˆ 3x32x32ì¸ CIFAR-10 Datasetì— ëŒ€í•´ì„œ ì‹¤í—˜ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— Input Dataì˜ dimensionì„ ë§ì¶°ì£¼ëŠ” ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
        "\n",
        "PyTorchì—ëŠ” ì´ë¥¼ ìœ„í•œ Upsample í´ë˜ìŠ¤ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
        "\n",
        "```\n",
        "nn.Upsample(size=(227,227))\n",
        "```\n",
        "\n",
        "> **ì£¼ì˜** : ì´ëŠ” ì‹¤í—˜ì˜ í¸ì˜ì„±ì„ ìœ„í•´ ì‚¬ìš©í•œ ë°©ì‹ì…ë‹ˆë‹¤. ì‹¤ì œë¡œ ë…¼ë¬¸ì„ ì¬êµ¬í˜„ í•  ë•Œì—ëŠ” ì‹¤í—˜ì´ ì§„í–‰ëœ Dataì™€ ë™ì¼í•œ dimensionì˜ Dataë¥¼ ì‚¬ìš©í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "+ ì¶”ê°€ë¡œ, Deep Learning ë¶„ì•¼ì—ì„œ ë§ì´ í™”ì œê°€ ë˜ì—ˆë˜ ì´ì•¼ê¸° ì¤‘ í•˜ë‚˜ê°€ Input dimensionì´ ë§ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì´ì—ˆìŠµë‹ˆë‹¤. ë…¼ë¬¸ì—ì„œ ì²«ë²ˆì§¸ Convolution Layerì—ì„œ filter sizeê°€ 11ì´ê³ , strideê°€ 4ë¼ëŠ” ê²ƒë§Œ ì–¸ê¸‰ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê·¸ ë•Œ output volumeì„ ê³„ì‚°í•´ ë³´ë©´ ì •ìˆ˜ê°€ ì•„ë‹™ë‹ˆë‹¤. ë§ì€ ì£¼ì¥ì´ ìˆì—ˆì§€ë§Œ ì €ìê°€ Padding 3ë¥¼ ë¹¼ë¨¹ì—ˆë‹¤ê³  ìƒê°í•´, ë³¸ êµ¬í˜„ì—ì„œë„ Padding 3ì„ ì¤¬ìŠµë‹ˆë‹¤.\n",
        "\n",
        "\n **ì¶”ê°€ 7.13 ìˆ˜ì •** : ì´ë¯¸ì§€ ì›ë˜ ì‚¬ì´ì¦ˆê°€ 3x227x227ì´ê³ , Paddingì€ ì—†ëŠ”ê²Œ ë§ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤. ((227 - 11) / 4 + 1 = 55) **ì•Œë ¤ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!**\n",
        "\n",
        "ë˜í•œ, AlexNetì€ GPU ë‘ ê°œì—ì„œ ëª¨ë¸ì„ ëŒë¦¬ê¸° ìœ„í•´ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. 2012ë…„ AlexNetì´ êµ¬í˜„ë  ë•Œì™€ ë‹¬ë¦¬ ì§€ê¸ˆì€ GPU ì„±ëŠ¥ì´ ë§ì´ ë°œì „í•˜ì—¬, í•˜ë‚˜ì˜ GPUì—ì„œë„ ì¶©ë¶„íˆ ì´ë¥¼ ì‹¤í–‰ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ë‚˜ì˜ GPUì—ì„œ ì‹¤í–‰ë˜ë„ë¡ ëª¨ë¸ì„ ìˆ˜ì •í•´ì„œ ì‹¤í—˜í•´ ë´…ì‹œë‹¤.\n",
        "\n",
        "ê·¸ë¦¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ìœ—ìª½ê³¼ ì•„ë˜ìª½ CNN Layerê°€ ìˆìŠµë‹ˆë‹¤. ì´ Layerë“¤ì„ í•˜ë‚˜ë¡œ í•©í•œë‹¤ë©´, feature ìˆ˜ê°€ ëŠ˜ì–´ë‚œë‹¤ê³  ìƒê°í•˜ë©´ ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì²« ë²ˆì§¸ CNN LayerëŠ” 48ê°œì˜ filterê°€ ë‘ ê°œ ìˆëŠ”ë°, ì´ë¥¼ 96ê°œì˜ filterê°€ ìˆë‹¤ê³  ìƒê°í•˜ë©´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "Fully-Connected Layer ë˜í•œ 2048 + 2048 = 4096ê°œì˜ featureë¥¼ ê°€ì§„ë‹¤ê³  ìƒê°í•˜ë©´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "**ì¬êµ¬í˜„ì€ Module APIë¥¼ ì‚¬ìš©í•´ë„ ì¢‹ê³ , Sequential APIë¥¼ ì‚¬ìš©í•´ë„ ì¢‹ìŠµë‹ˆë‹¤. ê¶Œíˆ¬ë¥¼ ë¹•ë‹ˆë‹¤!**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l01XXCQQP2G"
      },
      "source": [
        "## AlexNet Architecture Summary\n",
        "ë‹¤ìŒì€ ë…¼ë¬¸ì— ë‚˜ì˜¨ AlexNetì˜ êµ¬ì¡°ë¥¼ ìš”ì•½í•œ ê²ƒì…ë‹ˆë‹¤. êµ¬í˜„ì— ì°¸ê³ í•´ ì£¼ì„¸ìš”.\n",
        "### features\n",
        "|Layer|# of filters|Filter Size|Stride|Padding|Size of feature map|Activation|\n",
        "|:-----|:-----------|:----|:-----------|:------|:----------|:--|\n",
        "|Input Image|-|-|-|-|3x32x32|-|\n",
        "|Upsample|-|-|-|-|3x227x227|-|\n",
        "|Convolution 1|96|11x11|4|-|55x55x96|ReLU|\n",
        "|Max Pooling 1|-|3x3|2|-|27x27x96|-|\n",
        "|Convolution 2|256|5x5|1|2|27x27x256|ReLU|\n",
        "|Max Pooling 2|-|3x3|2|-|13x13x256|-|\n",
        "|Convolution 3|384|3x3|1|1|13x13x384|ReLU|\n",
        "|Convolution 4|384|3x3|1|1|13x13x384|ReLU|\n",
        "|Convolution 5|256|3x3|1|1|13x13x256|ReLU|\n",
        "|Max Pooling 3|-|3x3|2|-|6x6x256|-|\n",
        "\n",
        "### classifier\n",
        "|Layer|in_feature|out_feature|dropout rate|Activation|\n",
        "|:----|:---------|:----------|:-----------|:---------|\n",
        "|Flatten|-|-|-|-|\n",
        "|Dropout 1|-|-|0.5|-|\n",
        "|Fully-Connected 1|9216|4096|-|ReLU|\n",
        "|Dropout 2|-|-|0.5|-|\n",
        "|Fully-Connected 2|4096|4096|-|ReLU|\n",
        "|Fully-Connected 3|4096|10|-|-|\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sequential_accuracy"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-4\n",
        "\n",
        "model = None\n",
        "optimizer = None\n",
        "\n",
        "################################################################################\n",
        "# TODO: Reimplement AlexNet                                                    #\n",
        "################################################################################\n",
        "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "pass\n",
        "\n",
        "\n",
        "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "################################################################################\n",
        "#                                 END OF YOUR CODE                             #\n",
        "################################################################################\n",
        "\n",
        "train_part34(model, optimizer, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTQNIdymfthW"
      },
      "source": [
        "## Describe what you did\n",
        "\n",
        "ì¬êµ¬í˜„ì— ì„±ê³µí–ˆë‚˜ìš”? ì‹¤íŒ¨í–ˆë‹¤ë©´ ì–´ë–¤ ì ì´ ì–´ë ¤ì› ë‚˜ìš”? ë‹¤ë¥¸ ëª¨ë¸ê³¼ ë¹„êµí–ˆì„ ë•Œ ë” ì¢‹ì€ ì„±ëŠ¥ì´ ë‚˜ì™”ë‚˜ìš”? í˜¹ì€ ILSVRC'12ì™€ ë¹„ìŠ·í•œ ì„±ëŠ¥ì¸ê°€ìš”? ë§Œì•½ ê¸°ëŒ€í•˜ë˜ ì„±ëŠ¥ì´ ì•ˆ ë‚˜ì™”ë‹¤ë©´ ì–´ë–¤ ë¬¸ì œê°€ ìˆì—ˆì„ê¹Œìš”? ììœ ë¡­ê²Œ ìƒê°ì„ ì ì–´ì£¼ì„¸ìš”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4ueerblf7FI"
      },
      "source": [
        "**Answer:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq-i0xoUpR2E"
      },
      "source": [
        "# Part V. CIFAR-10 open-ended challenge\n",
        "\n",
        "ì´ sectionì—ì„œëŠ” CIFAR-10ì—ì„œ ì›í•˜ëŠ” ConvNet ì•„í‚¤í…ì²˜ë¥¼ ì‹¤í—˜í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì´ì œ ì—¬ëŸ¬ë¶„ì´ í•  ì¼ì€ ì•„í‚¤í…ì²˜, í•˜ì´í¼íŒŒë¼ë¯¸í„°, loss í•¨ìˆ˜, Optimizerë¥¼ ì‹¤í—˜í•˜ì—¬ 10ê°œ epoch ì´ë‚´ì— CIFAR-10 **Validation** ì„¸íŠ¸ì—ì„œ **70% ì´ìƒ** ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ëŠ” ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ìœ„ì—ì„œ í™•ì¸_ì •í™•ë„ ë° í›ˆë ¨ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `nn.Module` ë˜ëŠ” `nn.Sequential` APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì˜ ë§ˆì§€ë§‰ì— ì—¬ëŸ¬ë¶„ì´ ìˆ˜í–‰í•œ ì‘ì—…ì„ ì„¤ëª…í•˜ì„¸ìš”.\n",
        "\n",
        "ë‹¤ìŒì€ ê° êµ¬ì„± ìš”ì†Œì— ëŒ€í•œ ê³µì‹ API ë¬¸ì„œì…ë‹ˆë‹¤. í•œ ê°€ì§€ ì°¸ê³  ì‚¬í•­: \"spatial batch norm\" í´ë˜ìŠ¤ì—ì„œ í˜¸ì¶œí•˜ëŠ” ê²ƒì„ PyTorchì—ì„œëŠ” \"BatchNorm2D\"ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.\n",
        "\n",
        "* Layers in torch.nn package: http://pytorch.org/docs/stable/nn.html\n",
        "* Activations: http://pytorch.org/docs/stable/nn.html#non-linear-activations\n",
        "* Loss functions: http://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "* Optimizers: http://pytorch.org/docs/stable/optim.html\n",
        "\n",
        "\n",
        "### ì‹œë„í•´ ë³¼ë§Œí•œ ì¼:\n",
        "- **Filter size**: ìœ„ì—ì„œëŠ” 5x5ë¥¼ ì‚¬ìš©í–ˆëŠ”ë°, ë” ì‘ì€ í•„í„°ê°€ ë” íš¨ìœ¨ì ì¼ê¹Œìš”?\n",
        "- **Filters ìˆ˜**: ìœ„ì—ì„œëŠ” 32ê°œì˜ í•„í„°ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. í•„í„° ìˆ˜ê°€ ë§ê±°ë‚˜ ì ì„ìˆ˜ë¡ ë” íš¨ìœ¨ì ì¼ê¹Œìš”?\n",
        "- **Pooling vs Strided Convolution**: max poolingì„ ì‚¬ìš©í•˜ë‚˜ìš”, ì•„ë‹ˆë©´ Strided Convolutionë§Œ ì‚¬ìš©í•˜ë‚˜ìš”?\n",
        "- **Batch normalization**: Convolutional Layer ë’¤ì— spatial batch normalizationì„, affine ë ˆì´ì–´ ë’¤ì— vanilla batch normalizationì„ ì¶”ê°€í•´ ë³´ì„¸ìš”. ë„¤íŠ¸ì›Œí¬ê°€ ë” ë¹ ë¥´ê²Œ í›ˆë ¨ë˜ë‚˜ìš”?\n",
        "- **ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜**: ìœ„ì˜ ë„¤íŠ¸ì›Œí¬ì—ëŠ” ë‘ ê°œì˜ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ë ˆì´ì–´ê°€ ìˆìŠµë‹ˆë‹¤. ì‹¬ì¸µ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ë©´ ë” ì˜í•  ìˆ˜ ìˆë‚˜ìš”? ì‹œë„í•´ ë³¼ ë§Œí•œ ì¢‹ì€ ì•„í‚¤í…ì²˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
        "    - [conv-relu-pool]xN -> [affine]xM -> [softmax ë˜ëŠ” SVM]\n",
        "    - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax ë˜ëŠ” SVM]\n",
        "    - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax ë˜ëŠ” SVM]\n",
        "- **Global Average Pooling**: í‰í‰í•˜ê²Œ í•œ ë‹¤ìŒ ì—¬ëŸ¬ ê°œì˜ Affine ë ˆì´ì–´ë¥¼ ê°–ëŠ” ëŒ€ì‹  ì´ë¯¸ì§€ê°€ ì‘ì•„ì§ˆ ë•Œê¹Œì§€ Convolutionì„ ìˆ˜í–‰í•œ ë‹¤ìŒ(7x7 ì •ë„) Average Pooling ì—°ì‚°ì„ ìˆ˜í–‰í•˜ì—¬ 1x1 ì´ë¯¸ì§€ ì‚¬ì§„(1, 1 , Filter#)ì„ ì–»ì€ ë‹¤ìŒ (Filter#) ë²¡í„°ë¡œ ì¬í˜•ì„±í•©ë‹ˆë‹¤. ì´ ë°©ì‹ì€ [Google's Inception Network](https://arxiv.org/abs/1512.00567)ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤(ì•„í‚¤í…ì²˜ëŠ” í‘œ 1 ì°¸ì¡°).\n",
        "- **Regularization**: l2 ê°€ì¤‘ì¹˜ regulariztionë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ Dropoutì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "### Tips for training\n",
        "ì‹œë„í•˜ëŠ” ê° ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ì— ëŒ€í•´ í•™ìŠµ ì†ë„ì™€ ê¸°íƒ€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ì‘ì—…ì„ ìˆ˜í–‰í•  ë•Œ ëª…ì‹¬í•´ì•¼ í•  ëª‡ ê°€ì§€ ì¤‘ìš”í•œ ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤:\n",
        "\n",
        "- ë§¤ê°œë³€ìˆ˜ê°€ ì˜ ì‘ë™í•˜ëŠ” ê²½ìš° ìˆ˜ë°± ë²ˆì˜ ë°˜ë³µì„ í†µí•´ ê°œì„  íš¨ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ìœ„í•œ ê±°ì¹ ê³  ì„¸ë°€í•œ ì ‘ê·¼ ë°©ì‹ì„ ê¸°ì–µí•˜ì„¸ìš”. ëª‡ ë²ˆì˜ í•™ìŠµ ë°˜ë³µë§Œìœ¼ë¡œ ê´‘ë²”ìœ„í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ í…ŒìŠ¤íŠ¸í•˜ì—¬ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ” íŒŒë¼ë¯¸í„° ì¡°í•©ì„ ì°¾ëŠ” ê²ƒë¶€í„° ì‹œì‘í•˜ì„¸ìš”.\n",
        "- íš¨ê³¼ê°€ ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì´ëŠ” ëª‡ ê°€ì§€ íŒŒë¼ë¯¸í„° ì„¸íŠ¸ë¥¼ ì°¾ìœ¼ë©´ í•´ë‹¹ íŒŒë¼ë¯¸í„°ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë” ì„¸ë°€í•˜ê²Œ ê²€ìƒ‰í•˜ì„¸ìš”. ë” ë§ì€ epochì— ëŒ€í•´ í›ˆë ¨í•´ì•¼ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
        "- í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ì—ëŠ” ìœ íš¨ì„± ê²€ì‚¬ ì§‘í•©ì„ ì‚¬ìš©í•˜ê³ , ìœ íš¨ì„± ê²€ì‚¬ ì§‘í•©ì—ì„œ ì„ íƒí•œ ìµœìƒì˜ íŒŒë¼ë¯¸í„°ë¡œ ì•„í‚¤í…ì²˜ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ í…ŒìŠ¤íŠ¸ ì§‘í•©ì„ ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "### Going above and beyond\n",
        "ëª¨í—˜ì‹¬ì´ ê°•í•˜ë‹¤ë©´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ êµ¬í˜„í•  ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ ê¸°ëŠ¥ë„ ë§ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ëŠ¥ì„ ë°˜ë“œì‹œ êµ¬í˜„í•´ì•¼ í•˜ëŠ” ê²ƒì€ ì•„ë‹ˆì§€ë§Œ, ì‹œê°„ì´ ëœë‹¤ë©´ ê·¸ ì¬ë¯¸ë¥¼ ë†“ì¹˜ì§€ ë§ˆì„¸ìš”!\n",
        "\n",
        "- ëŒ€ì²´ optimizers: Adam, Adagrad, RMSprop ë“±ì„ ì‚¬ìš©í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "- Leaky ReLU, parametric ReLU, ELU ë˜ëŠ” MaxOutê³¼ ê°™ì€ ëŒ€ì²´ Activation í•¨ìˆ˜.\n",
        "- Model ensembles\n",
        "- Data augmentation\n",
        "- ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜\n",
        "  - [ResNets](https://arxiv.org/abs/1512.03385) ì´ì „ ë ˆì´ì–´ì˜ ì…ë ¥ì´ ì¶œë ¥ì— ì¶”ê°€ë©ë‹ˆë‹¤.\n",
        "  - [DenseNets](https://arxiv.org/abs/1608.06993) ì´ì „ ë ˆì´ì–´ì— ëŒ€í•œ ì…ë ¥ì´ ì„œë¡œ ì—°ê²°ë˜ëŠ” ê³³ì…ë‹ˆë‹¤.\n",
        "  - [ì´ ë¸”ë¡œê·¸ì—ì„œ ìì„¸í•œ ê°œìš”ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n",
        "\n",
        "### Have fun and happy training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWsuRLTjfoRa"
      },
      "outputs": [],
      "source": [
        "def train_part5(model, optimizer, epochs=1):\n",
        "    \"\"\"\n",
        "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
        "\n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "\n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    avg_losses = []\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    for e in range(epochs):\n",
        "        avg_loss = 0.0\n",
        "        for t, (x, y) in enumerate(loader_train):\n",
        "            model.train()  # put model to training mode\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "            scores = model(x)\n",
        "            loss = F.cross_entropy(scores, y)\n",
        "\n",
        "            # Zero out all of the gradients for the variables which the optimizer\n",
        "            # will update.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # This is the backwards pass: compute the gradient of the loss with\n",
        "            # respect to each  parameter of the model.\n",
        "            loss.backward()\n",
        "\n",
        "            # Actually update the parameters of the model using the gradients\n",
        "            # computed by the backwards pass.\n",
        "            optimizer.step()\n",
        "\n",
        "            if t % print_every == 0:\n",
        "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
        "                check_accuracy_part34(loader_val, model)\n",
        "                print()\n",
        "\n",
        "            avg_loss += loss.item()\n",
        "        avg_losses.append(avg_loss / len(loader_train))\n",
        "    return avg_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "open_ended_accuracy"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# TODO:                                                                        #\n",
        "# Experiment with any architectures, optimizers, and hyperparameters.          #\n",
        "# Achieve AT LEAST 70% accuracy on the *validation set* within 10 epochs.      #\n",
        "#                                                                              #\n",
        "# Note that you can use the check_accuracy function to evaluate on either      #\n",
        "# the test set or the validation set, by passing either loader_test or         #\n",
        "# loader_val as the second argument to check_accuracy. You should not touch    #\n",
        "# the test set until you have finished your architecture and  hyperparameter   #\n",
        "# tuning, and only run the test set once at the end to report a final value.   #\n",
        "################################################################################\n",
        "model = None\n",
        "optimizer = None\n",
        "experiment_name = \"model1_lr0.0001\"  # e.g., \"model1_sgd_lr0.1\", \"model2_adam_lr0.001\"\n",
        "# Change the above experiment_name to store the avg_losses while perserving\n",
        "# the previous avg_losses. Using the same value for experiment_name results in\n",
        "# overwriting the previous one.\n",
        "\n",
        "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "\n",
        "pass\n",
        "\n",
        "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "################################################################################\n",
        "#                                 END OF YOUR CODE                             #\n",
        "################################################################################\n",
        "\n",
        "# You should get at least 70% accuracy\n",
        "avg_losses = train_part5(model, optimizer, epochs=2)\n",
        "avg_losses = np.array(avg_losses)\n",
        "np.save(\"%s.npy\" % experiment_name, avg_losses)\n",
        "\n",
        "plt.plot(avg_losses)\n",
        "plt.title(\"Training Loss (%s)\" % experiment_name)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5samHtMggn_8"
      },
      "source": [
        "ì´ì „ì— ì‹¤í–‰í•œ `experiment_name` ì—¬ëŸ¬ ê°œë¥¼ ë¦¬ìŠ¤íŠ¸ ë‚´ì— ë‚˜ì—´í•´ ë³´ì„¸ìš”. ê° ì‹¤í—˜ì˜ ì†ì‹¤ í•¨ìˆ˜ ì¶”ì´ë¥¼ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdyq9pfCgqaz"
      },
      "outputs": [],
      "source": [
        "experiment_names = [\"model1_lr0.001\", \"model1_lr0.0001\"]\n",
        "\n",
        "for experiment_name in experiment_names:\n",
        "    avg_losses = np.load(\"%s.npy\" % experiment_name)\n",
        "    plt.plot(avg_losses, label=experiment_name)\n",
        "plt.title(\"Training Loss Comparison\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn0hm7nvpR2E"
      },
      "source": [
        "## Describe what you did\n",
        "\n",
        "ì•„ë˜ ì¹¸ì— ìì‹ ì´ ìˆ˜í–‰í•œ ì‘ì—…, êµ¬í˜„í•œ ì¶”ê°€ ê¸°ëŠ¥ ë°/ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ í›ˆë ¨í•˜ê³  í‰ê°€í•˜ëŠ” ê³¼ì •ì—ì„œ ë§Œë“  ê·¸ë˜í”„ì— ëŒ€í•œ ì„¤ëª…ì„ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85-8eL1mpR2E"
      },
      "source": [
        "**Answer:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM-B3G5ypR2F"
      },
      "source": [
        "## Test set -- run this only once\n",
        "\n",
        "ì´ì œ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¥¼ ì–»ì—ˆìœ¼ë¯€ë¡œ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ìµœì¢… ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤(best_modelì— ì €ì¥í•´ì•¼ í•¨). ì´ê²ƒì´ ìœ íš¨ì„± ê²€ì‚¬ ì„¸íŠ¸ ì •í™•ë„ì™€ ì–´ë–»ê²Œ ë¹„êµë˜ëŠ”ì§€ ìƒê°í•´ ë³´ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KGIAvAZpR2F"
      },
      "outputs": [],
      "source": [
        "best_model = model\n",
        "check_accuracy_part34(loader_test, best_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48ZsEUyiocf-"
      },
      "source": [
        "# Additional Part. Pretrained model ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "\n",
        "Part Vì—ì„œ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¥¼ ì–»ìœ¼ì…¨ë‚˜ìš”? PyTorchì˜ Modelì„ ì •ì˜í•˜ëŠ” ëŠ¥ë ¥ì€ ë§¤ìš° ê°•ë ¥í•˜ì§€ë§Œ, ë•Œë¡œëŠ” ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ë§Œë“¤ì–´ ë‘” Modelì„ í†µí•´ ë¹ ë¥´ê²Œ ì‹¤í—˜ì„ í•˜ê³  ì‹¶ì„ ë•Œë„ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ´ ë•Œë¥¼ ìœ„í•´ torchvisionë¥¼ í†µí•´ pre-trainedëœ Modelì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë‹¤ìŒì„ ì°¸ê³ í•˜ì„¸ìš”: [torchvision document](https://pytorch.org/vision/stable/models.html#classification)\n",
        "\n",
        "Modelì˜ êµ¬ì¡°ê°€ ê¶ê¸ˆí•œ ê²½ìš° print()ë¥¼ í†µí•´ ì‰½ê²Œ í™•ì¸í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLXA4juyol1y"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "\n",
        "# Download resnet50 pretrained\n",
        "resnet_pretrained = models.resnet50(pretrained=True)\n",
        "print(resnet_pretrained)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyK1w2VotW_C"
      },
      "source": [
        "## Pretrained model ìˆ˜ì •í•˜ê¸°\n",
        "print()ë¥¼ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆë“¯ì´, ë‹¤ìš´ ë°›ì€ ResNet Modelì˜ ë§ˆì§€ë§‰ LayerëŠ” out_features=1000ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ìš°ë¦¬ì˜ taskì—ì„œëŠ” Outputì´ 10ê°œ ì„ìœ¼ë¡œ, model êµ¬ì¡°ë¥¼ ì¡°ê¸ˆ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B726VCVjpcwK"
      },
      "outputs": [],
      "source": [
        "num_ftrs = resnet_pretrained.fc.in_features\n",
        "num_classes = 10\n",
        "\n",
        "# Modelì´ ê°€ì§„ 'fc'ë¼ëŠ” ì´ë¦„ì„ ê°€ì§„ Layerì— ì§ì ‘ ì ‘ê·¼í•´ ìˆ˜ì •í•´ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "resnet_pretrained.fc = nn.Linear(num_ftrs, num_classes)\n",
        "print(resnet_pretrained)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oUEPMcPsiBJ"
      },
      "source": [
        "## Fine tuning model ì„±ëŠ¥ í‰ê°€ í•˜ê¸°\n",
        "ì´ì œ Fine tuning í•œ Modelì˜ ì„±ëŠ¥ì„ í‰ê°€í•´ ë´…ì‹œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUaV2rF7LAX5"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(resnet_pretrained.parameters(), lr = 0.01)\n",
        "train_part34(resnet_pretrained, optimizer, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_l7diPcCqO_4"
      },
      "outputs": [],
      "source": [
        "check_accuracy_part34(loader_test, resnet_pretrained)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvtjmX24uhMg"
      },
      "source": [
        "ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¥¼ ì–»ìœ¼ì…¨ë‚˜ìš”?\n",
        "\n",
        "ì§ì ‘ ë§Œë“  Modelê³¼ ë¹„êµí•´ ë´¤ì„ ë•Œ ì–´ë–¤ modelì´ ë” ì„±ëŠ¥ì´ ì¢‹ì•˜ê³  ì™œ ê·¸ëŸ° ê²°ê³¼ê°€ ë‚˜ì™”ì„ê¹Œìš”?\n",
        "\n",
        "ë§Œì•½ í•™ìŠµì´ ì˜ ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆì„ê¹Œìš”?\n",
        "\n",
        "> [torchvision document](https://pytorch.org/vision/stable/index.html)ì— ìˆëŠ” ë‹¤ì–‘í•œ Modelë“¤ì„ ì‹œë„í•´ ë³´ë©´ì„œ ë¹„êµí•´ ë³´ë„ë¡ í•©ì‹œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOnK6v92vIwR"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# TODO:                                                                        #\n",
        "# Download any pretrained model from torchvision, then finetuning them         #\n",
        "################################################################################\n",
        "model = None\n",
        "optimizer = None\n",
        "\n",
        "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "\n",
        "pass\n",
        "\n",
        "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "################################################################################\n",
        "#                                 END OF YOUR CODE                             #\n",
        "################################################################################\n",
        "\n",
        "train_part34(model, optimizer, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qtKTBHduRa5"
      },
      "source": [
        "**Answer:**\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
