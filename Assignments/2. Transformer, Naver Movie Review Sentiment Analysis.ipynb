{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq4StkI_HpXa"
      },
      "source": [
        "# Programming Assingnment2 - Transformer, Naver Movie Review Sentiment Analysis\n",
        "안녕하세요 **AIKU 학회원 여러분**, 두 번째 과제는 지난 주에 배웠던 NLP 수업, 그 중에서도 Transformer 모델을 직접 구현해보는 과제입니다!\n",
        "\n",
        "NLP 관련해서는 CS224n 수업이 가장 유명하지만 아무래도 처음 공부하시는 분들이 과제를 풀기에는 많이 어려운 부분이 있어 최대한 쉽게 과제를 구상하려고 노력했습니다!\n",
        "\n",
        "Transformer 모델을 전체를 다 구현하는 것은 너무 어렵기 때문에 이번에는 Transformer의 Encoder 부분만 구현을 하고 이를 이용해서 감성분석 task를 수행할 예정입니다.\n",
        "\n",
        "네이버의 영화 리뷰 데이터를 바탕으로 source sentence를 Encoding한 후 Encoding된 결과를 linear classifier에 통과시켜 해당 리뷰가 긍정인지 부정인지를 분류하는 task를 수행하는 모델을 구현해 볼 예정입니다.\n",
        "\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/transformer-model-architecture.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1. 준비\n"
      ],
      "metadata": {
        "id": "Y40RpHx8VP-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-1. Pip install & Imports\n",
        "필요한 패키지를 pip를 이용해서 설치합니다."
      ],
      "metadata": {
        "id": "-K1sWdteVZ_r"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvCrh7LAHSMi"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "필요한 라이브러리를 import합니다\n",
        "\n",
        "그리고 device를 GPU로 바꿔줍니다!\n",
        "\n",
        "다만, 코드를 구현하는 과정에서는 **CPU 사용**을 권장드립니다.\n",
        "\n",
        "GPU가 가장 많이 필요한 단계는 학습하는 과정인데 구현하는 시간동안 colab의 GPU를 다 써버리면 막상 학습할 때 필요한 GPU 자원을 쓸 수 없게 됩니다. 따라서 코드를 모두 구현하고 train 코드가 잘 돌아가는지 확인한 뒤에 colab 상단 런타임 메뉴에서 런타임 유형을 GPU로 바꾼 뒤에 실행하시는 것을 권장드립니다!"
      ],
      "metadata": {
        "id": "ukTPpR96BGyZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dquM-bfUIW-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3ccb12-bca1-4637-cda9-6c1dc35b944d"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm, tqdm_notebook, trange\n",
        "import sentencepiece as spm\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('using device: ', device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJEj4JnOIHdp"
      },
      "source": [
        "### 1-2. Google Drive Mount\n",
        "Colab에서는 컴퓨터에 자원에 접근이 불가능 하므로 Google Drive에 파일을 올려 놓은 후 Google Drive를 mount 에서 로컬 디스크처럼 사용 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu_muOIjILVC",
        "outputId": "12ce95c8-11df-4ffc-f976-67d92190dfbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 지난 과제에서도 했던 과정이기 때문에 똑같이 Google Drive를 Mount해주시면 됩니다.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# data를 저장할 폴더 입니다. 환경에 맞게 수정 하세요.\n",
        "data_dir = \"/content/drive/My Drive/data\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-3. Dataset\n",
        "이번 과제에서 사용할 데이터셋입니다. 아래 링크에서 다운 받은 뒤 위에서 설정한 data를 저장할 폴더에 저장해주세요!\n",
        "\n",
        "colab에서 그 데이터를 직접 확인하는 코드는 작성해두지 않았습니다. 다만, 아래 사진을 첨부해드렸습니다. 데이터는 id, document, label로 구성되어 있고 id는 식별자, document는 리뷰 데이터, label은 긍정(1), 부정(0)을 의미합니다. 좀 더 자세하게 데이터가 어떻게 생겼는지 알고 싶으신 분들은 txt 파일을 열어보시면 확인할 수 있습니다!\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "https://drive.google.com/file/d/1Qg_Kd0iyMQ5zYOYGTosVxY00qS6y89lX/view?usp=drive_link\n"
      ],
      "metadata": {
        "id": "GSzC3DptVk07"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj8iGv_HIbQp"
      },
      "source": [
        "### 1-4. 폴더의 목록을 확인\n",
        "Google Drive mount가 잘 되었는지 확인하기 위해 data_dir 목록을 확인 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pjohaiGId95",
        "outputId": "3e96e471-0856-494c-a818-e3ec9ad1afbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for f in os.listdir(data_dir):\n",
        "  print(f)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kowiki.model\n",
            "kowiki.vocab\n",
            "ratings_test.txt\n",
            "ratings_train.txt\n",
            "ratings_train.json\n",
            "ratings_test.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOhCFxLPIdWx"
      },
      "source": [
        "### 1-5. Vocab 및 입력\n",
        "미리 만들어 놓은 vocab을 로딩 합니다.\n",
        "\n",
        "로딩된 vocab을 이용해 input을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u69gqsv_IkrL",
        "outputId": "11419e14-5fa2-4343-d94b-0b60c5088e6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# vocab loading\n",
        "vocab_file = f\"{data_dir}/kowiki.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "보통 영어를 NLP task를 처리할 때는 단어 기준으로 나누어도 크게 문제가 없지만 한국어는 한 단어가 보다 복잡하게 이루어져 있습니다. vocab을 사용해서 하나의 리뷰 문장을 나누어준 예시입니다.\n",
        "\n",
        "아래는 한국어 NLP를 어떤식으로 처리하는지에 대해 간단하게 보여주기 위해 추가한 코드입니다."
      ],
      "metadata": {
        "id": "H1EqFyOwCJo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "line = '뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아'\n",
        "pieces = vocab.encode_as_pieces(line)\n",
        "ids = vocab.encode_as_ids(line)\n",
        "print(line)\n",
        "print(pieces)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6di_Ko_yujV",
        "outputId": "4170d589-6382-4382-defc-4a7529a7e219"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n",
            "['▁', '뭐', '야', '▁이', '▁평', '점', '들은', '..', '..', '▁나', '쁘', '진', '▁않', '지만', '▁10', '점', '▁', '짜', '리는', '▁더', '더', '욱', '▁아니', '잖', '아']\n",
            "[3587, 5593, 3766, 8, 229, 3807, 162, 1920, 1920, 57, 5043, 3704, 101, 98, 129, 3807, 3587, 4351, 367, 228, 3840, 4267, 410, 5941, 3621]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12ZA0bI6Ip4s"
      },
      "source": [
        "## Part2. 영화 분류 데이터셋\n",
        "이제 본격적으로 트랜스포머 구현을 시작할 예정입니다. 그 전에 다운했던 데이터셋을 학습 과정에서 사용할 수 있도록 로드할 차례입니다.\n",
        "\n",
        "먼저 아래 'MovieDataSet' 클래스를 봅시다. 여러분이 따로 구현해야할 코드는 없지만 일반적으로 딥러닝에서 DataSet 클래스를 선언할 때 다음과 같이 \\_\\_len__과\n",
        " \\_\\_getitem__ 을 같이 선언해주게 됩니다. 이 형태에 대해서 한 번 확인해주고 넘어가면 좋을 것 같아요!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hRUATPWRo1L"
      },
      "source": [
        "\"\"\" 영화 분류 데이터셋 \"\"\"\n",
        "class MovieDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.labels = []\n",
        "        self.sentences = []\n",
        "\n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\") as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\") as f:\n",
        "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n",
        "                data = json.loads(line)\n",
        "                self.labels.append(data[\"label\"])\n",
        "                self.sentences.append([vocab.piece_to_id(p) for p in data[\"doc\"]])\n",
        "\n",
        "    def __len__(self):\n",
        "        assert len(self.labels) == len(self.sentences)\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return (torch.tensor(self.labels[item]),\n",
        "                torch.tensor(self.sentences[item]))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 'collate_fn' 함수는 하나의 batch 안에서 문장의 길이가 다 다른 경우에 batch 안에서 가장 긴 길이에 맞춰서 나머지 input을 padding 해주는 역할을 합니다."
      ],
      "metadata": {
        "id": "AyqG87jppKKr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjDhfnnWR2hi"
      },
      "source": [
        "def movie_collate_fn(inputs):\n",
        "    labels, enc_inputs = list(zip(*inputs))\n",
        "\n",
        "    enc_inputs = torch.nn.utils.rnn.pad_sequence(enc_inputs, batch_first=True, padding_value=0)\n",
        "\n",
        "    batch = [\n",
        "        torch.stack(labels, dim=0),\n",
        "        enc_inputs,\n",
        "    ]\n",
        "    return batch"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 DataLoader를 통해 데이터를 불러올 차례입니다."
      ],
      "metadata": {
        "id": "LFoZh93iXngJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIJqTZswR_Q5",
        "outputId": "81dda12c-9bb1-44d5-82c1-e2938c4738fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\" 데이터 로더 \"\"\"\n",
        "batch_size = 128\n",
        "train_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_train.json\")\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=movie_collate_fn)\n",
        "test_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_test.json\")\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=movie_collate_fn)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading /content/drive/My Drive/data/ratings_train.json: 100%|██████████| 149995/149995 [00:04<00:00, 31591.66 lines/s]\n",
            "Loading /content/drive/My Drive/data/ratings_test.json: 100%|██████████| 49997/49997 [00:01<00:00, 37378.11 lines/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class에서 __len__을 구현하면 dataset의 크기를 확인할 수 있습니다.\n",
        "print(len(train_dataset))\n",
        "# Dataset class에서 __getitem__을 구현하면 dataset을 index를 통해 접근할 수 있습니다.\n",
        "print(train_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxiN1rcqb9O8",
        "outputId": "40168244-9fc2-4360-a039-97a729da50ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149995\n",
            "(tensor(0), tensor([  26,  228, 4365, 1920,  132, 4351, 3587, 4351, 3922, 3628, 3857, 3760,\n",
            "         266, 3678, 3614]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part3. Transformer 구현에 필요한 함수\n",
        "처음부터 코딩을 하기 보다는 전체 코드의 흐름을 확인하고 각 함수가 왜 필요한지 그리고 서로 다른 class와 함수들이 어떻게 연결되어 있는지를 확인한 뒤에 코딩을 시작하시길 바랍니다!\n",
        "\n",
        "무턱대고 시작하면 너무 어려울 수 있어요!"
      ],
      "metadata": {
        "id": "r04onGp4EFUz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwm_ftQhKHJV"
      },
      "source": [
        "### 3-1. Positional Encoding\n",
        "**해당 함수는 따로 구현할 코드가 없습니다! Positional Encoding이 어떤 식으로 구현되는지 눈으로 확인해봅시다!**\n",
        "\n",
        "\n",
        "\n",
        "Positional Encoding 값을 구하기 위한 함수 입니다.\n",
        "Positional Encoding은 입력 문장 단어(토큰)들에 대한 위치정보를 인코딩하는 기술로, Transformer 모델의 입력 임베딩에 이 정보를 추가함으로써 단어의 상대적인 위치를 반영할 수 있습니다. 이렇게 함으로써 모델은 문장의 구조와 순서를 학습할 수 있게 됩니다.\n",
        "\n",
        "다음 코드는 Transformer에서 사용되는 대표적인 Positional Encoding 방법 중 하나인 Sinusodial Positional Encoding입니다. 이 방법은 고정된 함수로서 주기적인 값을 부여하여 위치정보를 인코딩합니다.\n",
        "\n",
        "Sinusodial Positional Encoding은 다음과 같은 수식을 사용하여 위치 인코딩 값을 계산합니다.\n",
        "$PE_{(pos,2i)}​ =sin(\\frac {pos}{10000^ {2i/d} model​}​ )$\n",
        "\n",
        "$PE_{(pos,2i+1)}​ =cos(\\frac {pos}{10000^ {2i/d} model​}​ )$\n",
        "\n",
        "여기서 $PE_{(pos, 2i)}$와 $PE_{(pos, 2i+1)}$는 Positional Encoding 행렬에서 $(pos, 2i)$와 $(pos, 2i+1)$ 위치에 해당하는 값을 의미하며, $pos$는 단어의 위치(position)를 나타내고, $i$는 인코딩 차원의 인덱스를 의미합니다. $d_{\\text{model}}$은 임베딩 차원의 크기를 나타냅니다.\n",
        "\n",
        "이렇게 구해진 Positional Encoding 행렬은 입력 임베딩과 더해져서 최종 입력으로 들어가게 되며, 모델은 이를 활용하여 문장의 구조와 순서를 이해하고 학습합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWTOw-L8KAV4"
      },
      "source": [
        "def PosEncoding(t_len, d_model):\n",
        "    i = torch.tensor(range(d_model))\n",
        "    pos = torch.tensor(range(t_len))\n",
        "    POS, I = torch.meshgrid(pos, i)\n",
        "    PE = (1-I % 2)*torch.sin(POS/10**(4*I/d_model)) + (I%2)*torch.cos(POS/10**(4*(I-1)/d_model))\n",
        "    return PE"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJRbra2GKjZx"
      },
      "source": [
        "### 3-2. Padding Mask\n",
        "Padding Mask를 구하기 위한 함수 입니다.\n",
        "\n",
        "Transformer 모델은 입력 시퀀스의 길이가 가변적일 수 있기 때문에, 입력 시퀀스의 길이를 일정하게 맞추기 위해 패딩(Padding)을 사용합니다. 패딩은 특정 값을 사용하여 시퀀스의 길이를 일정하게 맞추는 기술로, 주로 0과 같은 값이 사용됩니다.\n",
        "\n",
        "하지만 입력 시퀀스의 길이가 다르면, 이로 인해 Masking이 필요합니다. Masking은 패딩된 부분에 대해서는 모델이 실제로 입력값으로 처리하지 않도록 막는 것을 의미합니다. 이렇게 함으로써 모델이 패딩된 부분을 무시하고 실제 입력값에만 집중하여 처리할 수 있게 됩니다.\n",
        "\n",
        "\"get_attn_pad_mask\" 함수는 이러한 패딩 부분에 대한 Mask를 구하는 함수로, 주어진 입력 시퀀스에서 패딩된 위치에 0으로 채워진 마스크를 생성합니다. 이렇게 생성된 마스크는 실제 입력값이 있는 위치는 1로 표시되고, 패딩된 위치는 0으로 표시됩니다.\n",
        "\n",
        "즉, 데이터로더에서 각 batch 별로 가장 긴 길이에 맞추어 이미 padding을 했습니다. mask는 각 input에서 padding된 위치를 알려주는 역할을 합니다.\n",
        "\n",
        "Ex) [55, 43, 102, 43, 0, 0, 0] ➡ [1, 1, 1, 1, 0, 0, 0]\n",
        "\n",
        "이렇게 생성된 마스크는 attention score를 구할 때, mask에서 0에 해당하는 부분을 굉장히 작은 음수값으로 설정해 사실상 attention score 연산에서 제외될 수 있도록 도와줍니다. 이 때, 사용하는 함수는 'masked_fill\" 함수입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNN6p8r6KhzH"
      },
      "source": [
        "\"\"\" attention pad mask \"\"\"\n",
        "def get_attn_pad_mask(seq):\n",
        "    batch_size, seq_len = seq.shape[0], seq.shape[1]\n",
        "    tmp = torch.full_like(seq, fill_value=0).to(device)\n",
        "    mask = (seq != tmp).float()\n",
        "    mask = mask.reshape(batch_size, 1, seq_len).unsqueeze(1)\n",
        "\n",
        "    return mask"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7rndBaMj16n"
      },
      "source": [
        "### 3-3. Scaled Dot Product Attention\n",
        "**이번 과제에서 처음으로 직접 구현하게 될 코드입니다!**\n",
        "\n",
        "너무 어렵지 않게 구현해야 하는 내용을 자세히 설명해두었으니 아래 설명과 강의자료를 참고하며 열심히 따라와주시면 충분히 구현하실 수 있습니다.\n",
        "\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/scale_dot_product_attention.png)\n",
        "\n",
        "Self-Attention 메커니즘 중 하나로, 입력 시퀀스 내의 단어들 간의 관계를 학습하는 데 사용되는 기술입니다. 입력 시퀀스의 모든 단어를 서로 다른 관련성 가중치로 가중 평균하여 표현하는 방법입니다.\n",
        "\n",
        "[계산 방법]\n",
        "\n",
        "1) 입력 시퀀스를 Query(Q), Key(K), Value(V)로 세 가지 선형 변환을 거칩니다. 이를 통해 각각의 단어들을 차원을 다르게하여 쿼리, 키, 밸류로 표현합니다.\n",
        "\n",
        "2) 쿼리(Q)와 키(K) 간의 유사도를 계산합니다. 일반적으로는 내적(dot-product)을 사용하여 유사도를 계산합니다.\n",
        "\n",
        "3) 유사도를 키(K)의 차원 수로 나누어, 스케일링(scaling)을 적용합니다. 스케일링은 유사도를 안정적으로 유지하기 위해 사용됩니다.\n",
        "\n",
        "4) 계산된 유사도를 소프트맥스(softmax) 함수를 통해 정규화합니다. 이로써 입력 시퀀스 내의 모든 단어들 간의 관련성 가중치를 얻을 수 있습니다.\n",
        "\n",
        "5) 정규화된 가중치와 키(K)에 대응하는 밸류(V)를 가중 평균하여 Self-Attention 값을 얻습니다. 이는 입력 시퀀스 내의 각 단어에 대해 중요도를 반영한 표현을 얻는 것을 의미합니다.\n",
        "\n",
        "Scaled Dot-Product Attention은 행렬 연산을 통해 병렬적으로 처리되기 때문에 다수의 단어들 간의 관계를 빠르게 계산할 수 있습니다. 이로 인해 Transformer 모델은 긴 시퀀스에 대해서도 비교적 높은 효율성을 유지할 수 있게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byTcmFiLj2ok"
      },
      "source": [
        "\"\"\" scale dot product attention \"\"\"\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, d_head, dropout):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = math.sqrt(d_head)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        ################################################################################\n",
        "        # TODO:                                                                        #\n",
        "        # Complete Code for Scaled-Dot-Product-Attention                               #\n",
        "        ################################################################################\n",
        "\n",
        "\n",
        "        # 이미 변환된 Query, Key, Value를 input으로 받기 때문에 2번부터 진행해주시면 됩니다!\n",
        "\n",
        "        # 1. attn_score = /쿼리와 키 간의 유사도를 계산합니다, 이 때 scaling도 같이 진행해주시면 됩니다/\n",
        "        # Q, K, V: (bs, n_head, n_seq, d_head)\n",
        "\n",
        "        # attn_score = attn_score.masked_fill(attn_mask == 0, -1e9)\n",
        "        # 앞 서 설명한 masked_fill 함수입니다. attn_score의 결과에서 attn_mask가 0인 부분에 -1e9라는 값을 채워넣게 됩니다. 이 코드는 그대로 사용해주시면 됩니다!\n",
        "\n",
        "        # 2. attn_distribution = /attn_score를 바탕으로 attn_distribution을 구해주시면 됩니다/\n",
        "        # attn_distribution = self.dropout(attn_distribution)\n",
        "        # dropout에 대해서는 추후에 배우게 될 것입니다. dropout 역시 모델을 학습하는 과정에서 성능을 올리기 위한 방법 중 하나로 코드를 그대로 사용해주시면 됩니다!\n",
        "\n",
        "        # 3. attn_output = /attn_distribution을 바탕으로 Value vector들의 가중치 합을 구해주시면 됩니다/\n",
        "\n",
        "\n",
        "        ################################################################################\n",
        "        #                                 END OF YOUR CODE                             #\n",
        "        ################################################################################\n",
        "\n",
        "        return attn_output"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJMLVMjkj7_1"
      },
      "source": [
        "#### 3-4. MultiHeadAttention\n",
        "**이번 과제 구현에서 아마 가장 어려운 부분입니다!**\n",
        "\n",
        "대부분 행렬곱 연산 위주의 구현을 하게 될텐데 항상 차원을 맞추는 것에 유의해서 구현해주세요! 손으로 써가면서 따라가는 편이 쉬울겁니다! 어려우신 분은 그래도 대략적인 차원을 적어두었으니 참고하시면서 구현해주시면 되겠습니다!\n",
        "\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/multi_head_attention.png)\n",
        "\n",
        "마찬가지로 Self-Attention 메커니즘 중 하나로, 입력 시퀀스의 다양한 관점을 캡처하기 위해 여러 개의 Attention 헤드를 병렬로 사용하는 기법입니다. Self-Attention 레이어를 여러 개의 헤드로 나누고, 각 헤드에서 병렬로 Self-Attention을 수행하여 다양한 정보를 효과적으로 추출합니다.\n",
        "\n",
        "[계산 방법]\n",
        "\n",
        "1) 입력 시퀀스를 여러 개의 서로 다른 헤드로 분리합니다. 각 헤드는 별도의 Query(Q), Key(K), Value(V) 선형 변환을 적용합니다. 이를 통해 서로 다른 특성을 가진 Query, Key, Value를 추출할 수 있습니다.\n",
        "\n",
        "2) 각 헤드에서는 Scaled Dot-Product Attention을 사용하여 서로 다른 관점으로 입력 시퀀스의 단어들 간의 관계를 학습합니다. 각 헤드는 서로 다른 관점의 정보를 캡처하고, 다양한 종류의 패턴을 인식할 수 있게 됩니다.\n",
        "\n",
        "3) 계산된 Self-Attention 결과를 다시 하나의 행렬로 결합합니다. 이를 통해 서로 다른 헤드의 정보를 종합하여 최종 Self-Attention 결과를 얻을 수 있습니다.\n",
        "\n",
        "4) 병렬로 동작하는 여러 헤드를 가짐으로써, 모델은 다양한 관점에서 입력 시퀀스를 살펴볼 수 있고, 각 단어에 대해 다양한 특징을 추출하여 보다 풍부한 표현을 얻을 수 있게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCDPmr4sj8hz"
      },
      "source": [
        "\"\"\" multi head attention \"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, d_Q, d_K, d_V, num_head, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        ################################################################################\n",
        "        # TODO:                                                                        #\n",
        "        # Initialization of MultiHeadAteention Class                                   #\n",
        "        ################################################################################\n",
        "\n",
        "\n",
        "        # 아래 변수들을 올바르게 선언해주시면 됩니다!\n",
        "        # 1. self.d_model =\n",
        "        # 2. self.q_size =\n",
        "        # 3. self.k_size =\n",
        "        # 4. self.v_size =\n",
        "        # 5. self.num_head =\n",
        "        # q, k, v_size는 각 W_Q, W_K, W_V를 head의 개수로 나누었을 때 그 각각의 차원의 크기입니다.\n",
        "\n",
        "        # 6. self.W_Q =\n",
        "        # 7. self.W_K =\n",
        "        # 8. self.W_V =\n",
        "        # self-attention에서는 같은 input을 받아 Q, K, V의 선형 변환을 적용합니다. 이를 위한 W_Q, W_K, W_V를 구현해주시면 되겠습니다! 차원에 유의하세요.\n",
        "\n",
        "        # 9. self.scaled_dot_attn =\n",
        "        # 별도로 구현해놓은 ScaledDotProductAttention class를 가져옵니다. 이 때, ScaledDotProductAttention class를 잘 살펴보고 인자로 무엇을 넘겨야할지 생각해봅시다.\n",
        "\n",
        "\n",
        "        ################################################################################\n",
        "        #                                 END OF YOUR CODE                             #\n",
        "        ################################################################################\n",
        "\n",
        "        self.linear = nn.Linear(self.d_model, self.d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # Q, K, V: (bs, n_seq, d_model), q_s, k_s, v_s: (bs, n_head, n_seq, d_head)\n",
        "        batch_size = Q.size(0)\n",
        "\n",
        "\n",
        "        ################################################################################\n",
        "        # TODO:                                                                        #\n",
        "        # Complete Code for Multi-Head-Attention                                       #\n",
        "        ################################################################################\n",
        "\n",
        "\n",
        "        # input을 바탕으로 Query, Key, Value Vector를 구해줍니다. 각 Vector의 차원은 (bs, n_head, n_seq, d_head) 입니다.\n",
        "        # n_head는 head는 head의 개수, n_seq은 각 input의 길이, d_head는 head의 차원입니다.\n",
        "\n",
        "        # 1. q_s = /input을 바탕으로 Query Vector를 만들어주세요./\n",
        "        # input의 Q는 embedding 된 input이고 W_Q를 곱해서 Query Vector를 만들어야 합니다. 이 때 Query Vector의 차원은 (bs, n_head, n_q_seq, d_head) 입니다.\n",
        "\n",
        "        # 2. k_s = /input을 바탕으로 Key Vector를 만들어주세요./\n",
        "        # input의 K는 embedding 된 input이고 W_K를 곱해서 Key Vector를 만들어야 합니다. 이 때 Key Vector의 차원은 (bs, n_head, n_q_seq, d_head) 입니다.\n",
        "\n",
        "        # 3. v_s = /input을 바탕으로 Value Vector를 만들어주세요./\n",
        "        # input의 V는 embedding 된 input이고 W_V를 곱해서 Value Vector를 만들어야 합니다. 이 때 Value Vector의 차원은 (bs, n_head, n_q_seq, d_head) 입니다.\n",
        "\n",
        "        # 1,2,3번을 구현할 때 참고하시면 좋은 링크입니다!\n",
        "        # torch.Tensor.view https://pytorch.org/docs/stable/generated/torch.Tensor.view.html\n",
        "        # torch.transpose:  https://pytorch.org/docs/stable/generated/torch.transpose.html\n",
        "        # torch.permute:    https://pytorch.org/docs/stable/generated/torch.permute.html\n",
        "        # transpose와 permute의 용도는 유사합니다!\n",
        "\n",
        "        # 4. attn_output = /Scaled Dot Production을 수행해주세요 /\n",
        "        # 이 때 결과값은 attention output으로 attention output vector의 차원은 (bs, n_head, n_seq, d_head)가 됩니다.\n",
        "\n",
        "        # 5. output = /attn_output의 형태를 (bs, n_seq, d_model) 로 변환해주세요 /\n",
        "        # d_model의 값과 n_head, d_head의 관계가 어떻게 되는지 다시 한 번 생각해봅시다!\n",
        "\n",
        "        # output = self.linear(output)\n",
        "        # output = self.dropout(output)\n",
        "        # 위 두 줄의 코드는 그대로 사용해주시면 됩니다.\n",
        "\n",
        "\n",
        "        ################################################################################\n",
        "        #                                 END OF YOUR CODE                             #\n",
        "        ################################################################################\n",
        "\n",
        "        return output"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df1dKmZSkEiV"
      },
      "source": [
        "#### 3-5. FeedForwardNet\n",
        "**구현해야 할 함수입니다**\n",
        "\n",
        "가장 간단한 형태의 FeedForward Network의 형태로 설명을 읽고 순서에 맞추어 구현해주시면 되겠습니다.\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/feed-forward.png)\n",
        "\n",
        "Position-wise Feed-Forward Network은 각 위치(position)별로 독립적으로 적용되는 두 개의 선형 변환과 활성화 함수로 구성되는 네트워크입니다. 모델의 비선형성을 증가시키고, 입력 시퀀스의 각 위치에서 다양한 특징을 추출하는 데 도움이 됩니다.\n",
        "\n",
        "[설명]\n",
        "\n",
        "1) 입력 시퀀스의 각 위치별로, 먼저 하나의 선형 변환을 적용합니다. 이는 입력 시퀀스의 각 위치별로 입력 차원을 다른 차원으로 매핑하는 역할을 합니다.\n",
        "\n",
        "2) 활성화 함수로 주로 ReLU(Rectified Linear Unit)가 사용됩니다. 이 활성화 함수는 비선형성을 도입하여 모델이 더 복잡한 관계를 학습할 수 있도록 도와줍니다.\n",
        "\n",
        "3) 두 번째 선형 변환을 적용합니다. 이는 ReLU 활성화 함수를 통과한 결과를 다시 다른 차원으로 매핑하여 최종적인 출력 차원을 얻는 역할을 합니다.\n",
        "\n",
        "- PoswiseFeedForwardNet은 다음과 같은 수식으로 표현될 수 있습니다:\n",
        "\n",
        "- $PoswiseFeedForwardNet(x)=ReLU(xW_1​ +b_1​)W_2​ +b_2\n",
        "​ $\n",
        "\n",
        "여기서\n",
        "$x$는 입력 시퀀스의 각 위치에 대한 벡터를 나타내고, $W_1$과 $b_1$은 첫 번째 선형 변환의 가중치 행렬과 편향 벡터, $W_2$와 $b_2$는 두 번째 선형 변환의 가중치 행렬과 편향 벡터를 나타냅니다.\n",
        "\n",
        "모델이 입력 시퀀스의 각 위치에서 다양한 특징을 추출하고, 비선형성을 도입하여 더 풍부한 표현을 학습할 수 있도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDahw_QvkE6k"
      },
      "source": [
        "\"\"\" feed forward \"\"\"\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        ################################################################################\n",
        "        # TODO:                                                                        #\n",
        "        # Complete Code for Feed-Forward-Network                                       #\n",
        "        ################################################################################\n",
        "\n",
        "\n",
        "        # 1, 2번에서는 ReLU(xW_1 + b_1)을 구현해주시면 됩니다.\n",
        "        # 1. output =\n",
        "        # 2. output =\n",
        "        # output = self.dropout(output)\n",
        "        # 3번에서는 W_2 + b_2 부분을 구현해주시면 됩니다.\n",
        "        # 3. outpt =\n",
        "        # output = self.dropout(output)\n",
        "\n",
        "\n",
        "        ################################################################################\n",
        "        #                                 END OF YOUR CODE                             #\n",
        "        ################################################################################\n",
        "\n",
        "        return output"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Transformer\n",
        "본격적으로 Transformer의 구조를 직접 구현해볼 차례입니다!"
      ],
      "metadata": {
        "id": "1wMBpe1wlqkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-1. Encoder Layer\n",
        "**Encoder Layer를 직접 구현해봅니다!**\n",
        "\n",
        "앞 서 구현한 클래스를 바탕으로 Encoder Layer의 순서에 맞게 Encoder Layer를 구현해주시면 됩니다. 아래 이미지와 강의자료를 참고해주세요!\n",
        "\n",
        "Encoder Layer는 입력 시퀀스의 단어들을 인코딩하여 중간 표현을 생성하는 역할을 합니다.\n",
        "\n",
        "1) 입력 단어들에 대해 주변 단어들과의 관련성을 고려한 Self-Attention을 수행하여 풍부한 문맥 정보를 추출합니다.\n",
        "\n",
        "2) Feed-Forward Network를 통해 비선형성을 도입하고 다양한 특징을 추출합니다.\n",
        "\n",
        "3) Layer 간 잔차 연결과 Layer Normalization으로 Gradient Vanishing 문제를 완화하고, 모델 학습을 돕습니다.\n",
        "\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/encoder.png)\n"
      ],
      "metadata": {
        "id": "tUCnTyWnlwDb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My0FZFqFkns1"
      },
      "source": [
        "\"\"\" encoder layer \"\"\"\n",
        "class TF_Encoder_Block(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, num_head, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        d_heads = int(d_model / num_head)\n",
        "\n",
        "        self.MultiHeadAttention = MultiHeadAttention(d_model, d_heads, d_heads, d_heads, num_head, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # x: (bs, n_seq, d_model)\n",
        "\n",
        "        ################################################################################\n",
        "        # TODO:                                                                        #\n",
        "        # Complete Code for Encoder Layer                                              #\n",
        "        ################################################################################\n",
        "\n",
        "\n",
        "        # 1. attn_output = /Multi_Head_Attention 연산을 통해 attn_output을 계산해줍니다/\n",
        "        # 이 때, MultiHeadAttention class를 잘 확인하고 input을 어떻게 주어야 할지 고민해봅시다!/\n",
        "\n",
        "        # 2. output = /Residual Connection 부분을 구현해주시면 됩니다/\n",
        "        # Residual Connection은 MultiHeadAttention layer를 통과한 결과에 input을 더해주면 됩니다! output = layer(input) + input\n",
        "\n",
        "        # output = self.norm1(output)\n",
        "        # Layer Normalization 코드입니다. 그대로 사용해주시면 됩니다!\n",
        "\n",
        "        # 나머지 부분은 배운 내용과 위의 이미지를 참고해서 스스로 작성해봅시다!\n",
        "        # 일반적으로는 3줄의 코드가 더 필요합니다!\n",
        "\n",
        "\n",
        "        ################################################################################\n",
        "        #                                 END OF YOUR CODE                             #\n",
        "        ################################################################################\n",
        "\n",
        "        return output"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-2. Encoder\n",
        "**Encoder Layer를 구현했다면 전체 Trnasformer Encoder의 구조를 구현해봅시다.**\n",
        "\n",
        "해당 Encoder가 전체 input부터 output까지 출력하는 전체 구조입니다. 역시나 앞 서 구현한 클래스들을 바탕으로 구현해주시면 되고 Transformer Encoder에는 Encoder Layer(Block)이 여러 개(논문 기준 6개)가 포함된다고 설명드렸습니다. 이 점에 유의해서 구현해주세요!\n",
        "\n",
        "1) 입력에 대한 Position 값을 구하기: 각 단어의 상대적인 위치를 나타내는 Positional Encoding을 계산합니다.\n",
        "\n",
        "2) Input Embedding과 Position Embedding 더하기: 입력 시퀀스의 단어들을 임베딩하여 벡터로 표현한 후, Positional Encoding을 더합니다. 이를 통해 입력 시퀀스의 단어들은 고유한 위치 정보를 가진 임베딩으로 변환됩니다.\n",
        "\n",
        "3) 입력에 대한 Attention Pad Mask 구하기: Self-Attention 레이어에서 패딩 부분에 대한 마스크를 생성합니다. 이렇게 함으로써 모델이 패딩 부분을 무시하고, 실제 입력에만 집중할 수 있도록 돕습니다.\n",
        "\n",
        "4) for 루프를 돌며 각 layer를 실행하기: 여러 개의 EncoderLayer로 구성된 스택을 순차적으로 거칩니다. 각 EncoderLayer는 입력 시퀀스에 대한 인코딩을 수행하고, 다음 EncoderLayer로 전달하기 위해 중간 결과를 출력합니다.\n",
        "\n",
        "5) layer의 입력은 이전 layer의 출력 값: 스택의 첫 번째 EncoderLayer를 거칠 때는 이전 layer가 없으므로, Input Embedding과 Position Embedding의 결과가 첫 번째 EncoderLayer의 입력으로 사용됩니다. 이후의 EncoderLayer들은 이전 layer의 출력 값을 입력으로 받아 처리합니다.\n",
        "\n",
        "이렇게 입력 시퀀스에 대한 인코딩을 위해 Positional Encoding, Self-Attention, Residual Connection 등의 기법을 사용하여 입력 정보를 풍부하게 표현합니다. 이 과정을 여러 번 쌓아 올려서 Encoder를 형성하며, 최종적으로 입력 시퀀스의 문맥 정보를 잘 반영한 중간 표현을 얻습니다."
      ],
      "metadata": {
        "id": "X2qmZ8FumK1b"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuRgl12Ekg9F"
      },
      "source": [
        "\"\"\" encoder \"\"\"\n",
        "class TF_Encoder(nn.Module):\n",
        "    def __init__(self, voc_size, d_model, d_ff, num_layer, num_head, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_layer = num_layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Embedding\n",
        "        self.src_embed = nn.Embedding(num_embeddings=voc_size, embedding_dim = d_model)\n",
        "        # Encoding Blocks\n",
        "        self.enc_blocks = TF_Encoder_Block(d_model, d_ff, num_head, dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (bs n_seq), x_embed: (bs, n_seq, d_model)\n",
        "        x_embed = self.src_embed(x)\n",
        "        x_embed = self.dropout(x_embed)\n",
        "        p_enc = PosEncoding(x_embed.shape[1], x_embed.shape[2]).to(device)\n",
        "        x_embed = x_embed + p_enc\n",
        "        mask = get_attn_pad_mask(x)\n",
        "\n",
        "        ################################################################################\n",
        "        # TODO:                                                                        #\n",
        "        # Complete Code for Encoder                                                    #\n",
        "        ################################################################################\n",
        "\n",
        "\n",
        "        # 수업시간에도 설명했듯이 Transformer는 Encoder block을 여러개 사용합니다. num_layer의 개수만큼 Encoder Block을 쌓아주시면 됩니다!\n",
        "        # 이 때, 각 Encoder block에는 최초 embeding된 input(or Encoder block을 통과한 결과) 와 mask(attention_mask)가 input으로 주어집니다!\n",
        "\n",
        "\n",
        "        ################################################################################\n",
        "        #                                 END OF YOUR CODE                             #\n",
        "        ################################################################################\n",
        "        return out"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Naver 영화 리뷰 감성분석 모델\n",
        "\n",
        "이제는 구현한 Transformer를 바탕으로 Naver 리뷰의 감성을 분석해볼 차례입니다. Transformer Encoder로 input sentence를 Encoding한 뒤 해당 Encoding을 가장 간단한 classifier에 통과시켜 해당 리뷰가 긍정(1)인지 부정(0)인지를 분류하는 Classification 모델입니다."
      ],
      "metadata": {
        "id": "fqOwSFscmyYC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xM6W55dzPrZ"
      },
      "source": [
        "\"\"\" naver movie classfication \"\"\"\n",
        "class MovieClassification(nn.Module):\n",
        "    def __init__(self, enc_input_size, enc_d_model, enc_d_ff, enc_num_layer, enc_num_head, dropout):\n",
        "        super().__init__()\n",
        "        self.encoder = TF_Encoder(voc_size = enc_input_size,\n",
        "                                  d_model = enc_d_model, d_ff=enc_d_ff,\n",
        "                                  num_layer=enc_num_layer, num_head=enc_num_head,\n",
        "                                  dropout=dropout)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,None)),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(in_features = enc_d_model, out_features=enc_d_model),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(in_features = enc_d_model, out_features = 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, enc_inputs):\n",
        "        # input을 encoder, 즉 Transformer Encoder를 통해 Encoding합니다.\n",
        "        enc_outputs = self.encoder(enc_inputs)\n",
        "        # Encoding한 결과를 classifier에 통과시켜 해당 리뷰의 감성을 예측합니다.\n",
        "        logits = self.classifier(enc_outputs).flatten()\n",
        "        return logits"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI3VfPuVS6s8"
      },
      "source": [
        "## 6. 네이버 영화 리뷰 감성분석 모델 데이터 학습\n",
        "아래는 train 및 test 코드입니다. test 부분의 빈칸은 train 부분과 같은 부분이므로 train 코드를 구현해주신 뒤에 참고하셔서 적어주시면 되겠습니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-1. Train"
      ],
      "metadata": {
        "id": "fnK5DEk-owbz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc9AcaiYTKK2"
      },
      "source": [
        "\"\"\" 모델 epoch 학습 \"\"\"\n",
        "def train_epoch(epoch, model, criterion, optimizer, train_loader, clip):\n",
        "    ## 인자\n",
        "    # - epoch: 현재 epoch 번호를 나타냅니다.\n",
        "    # - model: 학습할 딥러닝 모델입니다.\n",
        "    # - criterion: 학습 손실을 계산하는 데 사용되는 손실 함수입니다.\n",
        "    # - optimizer: 최적화를 수행하는데 사용되는 optimizer입니다.\n",
        "    # - train_loader: 학습 데이터를 불러오는 데 사용되는 데이터 로더입니다.\n",
        "    # - clip: 그래디언트 클리핑에 사용되는 값으로, explosion를 방지합니다.\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    with tqdm_notebook(total=len(train_loader), desc=f\"Train {epoch}\") as pbar:\n",
        "      '''tqdm_notebook은 노트북에서 진행 상태를 시각적으로 표시하는 데 사용되는 라이브러리입니다.\n",
        "      train_loader의 총 반복 횟수를 total로 설정하고,\n",
        "      현재 epoch를 진행하는 동안의 설명을 desc로 지정하여 진행 표시줄을 생성합니다.'''\n",
        "      for i, batch in enumerate(train_loader):\n",
        "            labels = batch[0].float().to(device)\n",
        "            enc_inputs = batch[1].to(device)\n",
        "\n",
        "            ################################################################################\n",
        "            # TODO:                                                                        #\n",
        "            # Complete Train Code                                                          #\n",
        "            ################################################################################\n",
        "\n",
        "\n",
        "            # 1. /옵티마이저의 그래디언트를 초기화해 주세요./\n",
        "\n",
        "            # 2. output = /모델에 인코더 입력을 전달하여 출력을 얻습니다./\n",
        "\n",
        "\n",
        "            # output = output.contiguous().view(-1)  # 연속적인 1차원 텐서로 변환합니다.\n",
        "            # label = labels.contiguous().view(-1) # 연속적인 1차원 텐서로 변환합니다\n",
        "            # 실행하실때 그대로 사용해주시면 됩니다! 주석처리 해제!\n",
        "\n",
        "            # 3. loss = / 손실 함수를 사용하여 loss을 계산합니다./\n",
        "\n",
        "            # loss_val = loss.item()\n",
        "            # losses.append(loss_val)\n",
        "            # 실행하실때 그대로 사용해주시면 됩니다! 주석처리 해제!\n",
        "\n",
        "            # 4. /역전파를 수행하여 그래디언트를 계산합니다./\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            # Gradient cliping을 해주는 코드입니다.\n",
        "\n",
        "            # 5. 옵티마이저를 사용하여 모델 파라미터를 업데이트합니다./\n",
        "\n",
        "\n",
        "            ################################################################################\n",
        "            #                                 END OF YOUR CODE                             #\n",
        "            ################################################################################\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-2. Evaluate"
      ],
      "metadata": {
        "id": "Ftnm8wyeoz4e"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LewCUJDHTJjd"
      },
      "source": [
        "\"\"\" 모델 epoch 평가 \"\"\"\n",
        "def get_binary_metrics(y_pred, y):\n",
        "    # find number of TP, TN, FP, FN\n",
        "    # 평가 metric으로 가장 흔하게 사용되는 F1 Score입니다. 자세한 내용은 https://en.wikipedia.org/wiki/F-score 을 참고해주세요!\n",
        "    TP=sum(((y_pred == 1)&(y==1)).type(torch.int32))\n",
        "    FP=sum(((y_pred == 1)&(y==0)).type(torch.int32))\n",
        "    TN=sum(((y_pred == 0)&(y==0)).type(torch.int32))\n",
        "    FN=sum(((y_pred == 0)&(y==1)).type(torch.int32))\n",
        "    accy = (TP+TN)/(TP+FP+TN+FN)\n",
        "\n",
        "    recall = TP/(TP+FN) if TP+FN!=0 else 0\n",
        "    prec = TP/(TP+FP) if TP+FP!=0 else 0\n",
        "    f1 = 2*recall*prec/(recall+prec) if recall+prec !=0 else 0\n",
        "\n",
        "    return accy, recall, prec, f1\n",
        "\n",
        "\n",
        "def eval_epoch(model, data_loader, criterion):\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    epoch_accy =0\n",
        "    epoch_recall =0\n",
        "    epoch_prec =0\n",
        "    epoch_f1 =0\n",
        "    with tqdm_notebook(total=len(data_loader), desc=f\"Valid\") as pbar:\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            labels = batch[0].float().to(device)\n",
        "            enc_inputs = batch[1].to(device)\n",
        "\n",
        "            ################################################################################\n",
        "            # TODO:                                                                        #\n",
        "            # Complete Evaluation Code                                                     #\n",
        "            ################################################################################\n",
        "\n",
        "\n",
        "            # /옵티마이저 초기화/\n",
        "            # output =\n",
        "\n",
        "            # output =\n",
        "            # labels =\n",
        "            # loss를 구하기 위해 1차원 텐서로 변환\n",
        "\n",
        "            # loss =\n",
        "\n",
        "\n",
        "            ################################################################################\n",
        "            #                                 END OF YOUR CODE                             #\n",
        "            ################################################################################\n",
        "\n",
        "            accy, recall, prec, f1 = get_binary_metrics((output>=0).long(), labels.long())\n",
        "            epoch_accy += accy\n",
        "            epoch_recall += recall\n",
        "            epoch_prec += prec\n",
        "            epoch_f1 += f1\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "    # show accuracy\n",
        "    print(f'\\tAccuracy: {epoch_accy/(len(data_loader)):.3f}')\n",
        "\n",
        "    return epoch_loss / len(data_loader)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-3. Hyperparamter Tuning\n",
        "\n",
        "좋은 모델을 구현하는 것도 중요하지만 모델의 성능은 Hyper Parameter에 따라 크게 달라집니다. 특히, learning rate와 epoch가 가장 크게 영향을 주며 hidden_layer의 차원에 따라서도 성능이 달라질 수 있습니다! 모델을 성공적으로 구현했다면 더 좋은 성능을 가진 모델을 스스로 한 번 찾아보세요!"
      ],
      "metadata": {
        "id": "3ljgcPGUos7x"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62PrcR_qTs3G"
      },
      "source": [
        "# Hyperparameter\n",
        "################################################################################\n",
        "# TODO:                                                                        #\n",
        "# Hyperparameter Tuning                                                        #\n",
        "################################################################################\n",
        "\n",
        "\n",
        "learning_rate =         # 1e-3 ~ 1e-5\n",
        "n_epoch = 10                # epoch 수가 더 늘어나면 좋을까요? 학습을 많이 하니까?\n",
        "enc_d_model = 256           # 각 단어를 embedding 할 때, 각 embedding vector의 차원을 나타냅니다. 2^n 형태로 많이 사용합니다.\n",
        "enc_d_ff = 512              # FeedForwardNetwork에서 사용되는 차원입니다. 2^n 형태로 많이 사용합니다.\n",
        "\n",
        "\n",
        "################################################################################\n",
        "#                                 END OF YOUR CODE                             #\n",
        "################################################################################\n",
        "\n",
        "\n",
        "\n",
        "# 이 외에도 아래 변수들도 Hyperparmeter에 해당하지만 이 부분은 고정해주세요. 위의 Hyperparameter를 tuning해보면서 결과에 큰 차이가 있는지 확인해봅시다!\n",
        "enc_num_head = 8            # MultiHeadAttention에서 몇개의 head를 사용할지를 정합니다.\n",
        "enc_num_layer = 6           # 논문에 맞춰서 똑같이 6개로 설정했습니다.\n",
        "CLIP = 1                    # Exploding Gradient가 일어날 때 Gradient를 줄여주기 위해 설정하는 값입니다.\n",
        "\n",
        "dropout = 0.1               # 이 부분은 자세히 배우지 않은 걸로 알고 있어서 추가하진 않았지만 궁금하신 분들은 dropout 값도 tuning 해 보셔도 좋을 것 같습니다!\n",
        "\n",
        "\n",
        "# 모델을 설정합니다\n",
        "model = MovieClassification(enc_input_size=8007, enc_d_model=enc_d_model, enc_d_ff=enc_d_ff, enc_num_layer=enc_num_layer, enc_num_head=enc_num_head, dropout=dropout)\n",
        "model.to(device)\n",
        "\n",
        "# 손실함수와 Optimization 형태를 설정해줍니다.\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 가장 성능이 좋은 모델을 저장하기 위해 valid_loss가 가장 작은 값을 찾아야 합니다. 왜 train_loss가 아니라 valid_loss로 판단하는지 생각해봅시다!\n",
        "best_valid_loss = float('inf')"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-4. Train\n",
        "이제 직접 학습을 진행해볼 차례입니다! Hyperparameter에 따라 값이 달라지기는 하겠지만 대략적으로 가장 높은 F1 score가 0.8 이상 나오면 모델이 잘 구현된 것입니다.\n",
        "\n",
        "**모델의 학습이 실제로 되는지 궁금하신 분들은 아래 train 코드를 실행하기 전에 그 아래 inference부터 해보셔도 좋을 것 같습니다!**\n",
        "\n",
        "모델이 학습이 하나도 되지 않았을 때 감성 분석을 어떻게 하는지 살펴봅시다!"
      ],
      "metadata": {
        "id": "-SHCGv4QrS6j"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mATLq-JjUAa5"
      },
      "source": [
        "for epoch in range(n_epoch):\n",
        "    train_loss = train_epoch(epoch, model, criterion, optimizer, train_loader, CLIP)\n",
        "    valid_loss = eval_epoch(model, test_loader, criterion)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-5. Inference\n",
        "학습된 모델로 직접 리뷰를 몇개 작성해보고 해당 리뷰의 감성을 분석해봅시다. 여기서는 아주 간단하게 모델이 예측한 값이 0.5 이하(0에 가까우면)일 때 부정, 이상(1에 가까우면)일 때 긍정으로 판단하겠습니다.\n",
        "\n",
        "당연히 모델 성능에 따라 다 맞추지는 못할 것입니다. 비교적 쉬운 문장으로 테스트 해주시면 좋을 것 같고 이 부분이 과제의 마지막 부분입니다! 본인의 예시를 5가지정도(더 많으면 좋아요) 만들어서 모델이 잘 예측하는지 확인해주세요!"
      ],
      "metadata": {
        "id": "6Z8PrEWcrmYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(input) :\n",
        "  sen = [vocab.piece_to_id(p) for p in input]\n",
        "\n",
        "  input = torch.Tensor(sen).long()\n",
        "  input = input.reshape(1, -1).to(device)\n",
        "\n",
        "  # 학습을 하지 않은 경우 저장된 model.pt가 없기 때문에 아래 코드를 주석처리해주셔야 합니다!\n",
        "  model.load_state_dict(torch.load('model.pt'))\n",
        "\n",
        "  output = model(input)\n",
        "  if output < 0.5:\n",
        "    sentiment = '부정'\n",
        "  else:\n",
        "    sentiment = '긍정'\n",
        "  return sentiment"
      ],
      "metadata": {
        "id": "2jk5DPL-PT_r"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "your_example = [\"예시 문장1\", \"예시 문장2\", \"예시 문장3\", \"예시 문장4\", \"예시 문장5\"]\n",
        "\n",
        "for sentence in your_example:\n",
        "  output = inference(sentence)\n",
        "  print(f\"리뷰 \\\"{sentence}\\\"에 대한 감성은 <{output}>입니다.\")"
      ],
      "metadata": {
        "id": "--FzCC3mNWv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Conclusion\n",
        "지금까지 Transformer 형태를 가장 간단하게 활용할 수 있는 과제를 직접 구현해보았습니다. 모델을 구현하고 모델을 학습하고, 그리고 추론까지 해보는 과정을 겪었는데 전반적인 과정에 대해서 간단한 소감을 작성해주시고 과제 중간 중간에 생각해볼만한 질문들을 몇가지 남겨두었습니다. 이 부분에 대한 답변은 필수는 아니지만 이런 부분에 대해서 답변해주셔도 좋습니다!\n",
        "\n",
        "특히 가장 마지막 추론 단계에서 모델이 정답을 잘 맞췄는지, 그렇다면 그 이유는 무엇이고 그럼에도 모델이 갖는 한계점은 무엇일지...\n",
        "\n",
        "만약 잘 맞추지 못했다면 왜 그럴지, 그렇다면 무엇을 고쳐야할지, 잘 모르겠다면 모델의 한계점 등에 대해서 자유롭게 작성해주세요!\n",
        "\n",
        "(모델이 잘 작동하지 못하는 이유에는 정답이 없습니다! 따라서 너무 어렵게 생각하지는 말아주세요! 추가로 분량은 너무 길 필요는 없습니다! 간단하게... 그치만 너무 짧게는 말고요...!)"
      ],
      "metadata": {
        "id": "gpm7EmIA_sv-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n"
      ],
      "metadata": {
        "id": "3f-qMouaAnBz"
      }
    }
  ]
}